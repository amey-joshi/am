\documentclass{article}
\usepackage{amsmath, amssymb, amsthm, amsfonts}
\numberwithin{equation}{section}
\DeclareMathOperator{\pr}{P}
\renewcommand{\vec}[1]{\mathbf{#1}}

\title{A Review of Mortality Models}
\author{To be filled}
\date{Sep-2020}
\begin{document}
\maketitle
\section{Introduction}\label{s0}
Although it is very difficult to predict the behaviour of a member of a large
population one can often make statistical statements about the same population 
with much greater 
confidence. For example, it is impossible to predict when a particular 
radioactive atom will decay but one can make an accurate prediction of how 
many atoms will decay in a long enough time interval. Likewise, it is not
possible to predict the time of death of an individual although one can reliably
predict how many people from a large enough group will survive past a certain
date in future. Actuaries knew this statistical fact long before the 
mathematical foundations of the theory of probability were laid. The 
mathematical models they to describe how deaths occur in a given society are
called `mortality models'.

The death of an individual in a population or the decay of a radioactive atom
is an event happening to a member of the population. Likewise, the failure of
a machine, an occurrence of an event, the duration of a certain phase in an
economy are all different manifestations of the same phenomenon in which 
something happens that significantly alters the future of the member of the
population. Death terminates an individual's existence, radioactive decay
transforms the atom, failure renders a machine unusable and economies change 
after occurrences of certain cataclysmic events. Mortality of an individual
is akin to reliability of a machine. Life of an individual is similar to
the duration of a certain phase of business cycle. As a result, the 
theoretical tools used to study these outwardly different phenomena are similar 
to each other. 
Mortality analysis in actuarial science is called survival analysis is 
statistics, reliability theory in engineering, duration analysis in economics 
and event history analysis in sociology.

John Graunt, an English haberdasher, was perhaps the world's first demographer
and epidemiologist. In spite of the rudimentary mathematical tools available
in the seventeenth century, he was able to publish the first life tables. They
were based on the `Bills of Mortality' published in the parishes of London
every Thursday. The data was not best suited for constructing life tables but
that was the only one available in Graunt's time. Graunt admitted the 
inadequacy of his approach. Edmund Halley, the man after whom a comet is 
named, could get demographic data of a much better quality from the city of
Wroclaw in Poland. It had the age and sex of the dead individuals. Halley
used this data to build life tables of a greater accuracy than Graunt's. He
also demonstrated how to use the life tables to compute annuities. Graunt's
and Halley's work was entirely empirical, keeping with the times in which
it was done. Using their life tables was also quite laborious. With the 
invention of Calculus in the late seventeenth century and the development of 
the rudimentary ideas of a mathematical function, it became possible to build
theoretical models of human mortality.

Traditionally, mortality models studied existing demographic data to produce
mortality tables. They described mortality at a fixed point in time. The pace 
of technology development was quite slow in the times when the first mortality
models were proposed. Therefore, the mortality data and the models describing
them appeared to be like a natural characteristic of the human species. They
sufficed the needs of the fledgling insurance industry to compute projections
of annuities.

However, the advancement in health science since the early years of the 
twentieth century, the relative peace in the western world since the second 
world war and abundance of food in the rich world resulted in a change in
historical mortality patterns. Pension funds started realizing that annuities
were being drawn for longer than expected periods. As the population in the
developed countries started greying the pension funds had the additional 
problem of a higher annunity obligations and a lower contribution from newer
workers. Pension funds now have a keen interest in understanding how mortality 
rates will evolve in the future. They now want to forecast mortality than just
produce models of the current mortality. 

Demographic forecasting predates mortality forecasting. Economists like Thomas
Malthus predicted that the human population will grow to such an extent that
there will not be enough to feed everyone. This dire prediction meant that the
politicians and the economists had a keen desire to predict how populations
will grow and whether there will be enough food for everyone. As a result, many 
statistical methods developed in Demography were readily available for mortality
forecasting. This need for forecasting was also coeval with the developments
in the modern theory of mathematical statistics and the foundations of
probability. It is not a coincidence that the early mortality models were
mathematical functions while the later ones are stochastic models.

Mortality models, being mathematical functions, produce a single curve for
a given set of its parameters. On the other hand, mortality forecasts are a
collection of curves or a family of probablity distributions. Their output
is accompanied with appropriate confidence intervals to indicate the 
uncertainty in their reported values.

In this article we shall review the development mathematical models to study
and forecast mortality in large enough populations of people.

\section{de Moivre's law}\label{s1}
An annuity is a lifelong payment made to an individual by a company. The 
company would want to estimate how much annuity its customers will consume
before they cease to exist. In order to estimate its yearly obligations, the
company would need to know what proportion of its customers will survive
past various points in the future. It to this problem that de Moivre 
\cite{de1731annuities} addresses his treatise. In order to estimate the value
of annuities one must consider the interest earned by the company's assets and
the probability of survival of its customers. In de Moivre's days the interest
rates were controlled by law. Therefore, he focused on estimating the 
probability of survival of the company's customers.

Developed in the 18th century, de Moivre's model was indeed quite simple. 
He assumed that there is a certain age, $\omega$ beyond which no human 
survives. Further, as time goes by the probability of a person's survival
decreases. The probability that a new born person will survive at least
$x$ years was proposed to be
\begin{equation}\label{s1e1}
s(x) = 1 - \frac{x}{\omega}, 
\end{equation}
where $0 \le x \le \omega$. The function $s$, called the survival function,
has the following characteristics
\begin{enumerate}
\item It is a decreasing function of $x$.
\item $s(x = 0) = 1$ and $s(x = \omega) = 0$. In between these age limits, it
is a linear function of $x$.
\end{enumerate}
de Moivre proposed the use of different $\omega$'s for different age groups, 
making his model piece-wise linear. We will examine a few immediate 
consequences of de Moivre's model and while doing so we will introduce the
notation common in actuarial literature \cite{jordan1967society}. The symbol
$(x)$ denotes life aged $x$. If $k$ is an estimate of the size of a population
born together then the number of people alive at age $x$ is $l_x = ks(x)$.
The number of people who will die in the interval $x$ to $x + 1$ is $d_x = l_x
- l_{x+1}$. The probability that $x$ will survive for another $n$ years is
\begin{equation}\label{s1e2}
{}_np_x = \frac{l_{x+n}}{l_x} = \frac{s(x+n)}{s(x)}.
\end{equation}
The probability that a person will die within next $n$ years of $x$ is
\begin{equation}\label{s1e3}
{}_nq_x = 1 - {}_np_x.
\end{equation}
It is common to denote ${}_1p_x$ as $p_x$ and ${}_nq_x$ as $q_x$. The `force
of mortality' is defined as
\begin{equation}\label{s1e4}
\mu(x) = -\frac{s^\prime(x)}{s(x)}, 
\end{equation}
where a $s^\prime$ denotes the derivative of $s$ with respect to $x$. The 
force of mortality is also called the hazard function in the statistical
literature. The hazard function or the `force of mortality' is an individual's
susceptibility to die. Its reciprocal is the individual's resistance to death. 
de Moivre's law proposes that a person's resistance to die varies linearly over
time. That is,
\begin{equation}\label{s1e5}
\nu(x) = \frac{1}{\mu(x)} = \omega - x.
\end{equation}
If $x_0 = a, x_1 = a + d, x_2 = a + 2d, ..., x_n = a + nd$ then it is clear 
that $\nu(x_n)$ form an algebraic progression. This point may seem to be just a 
mathematical characteristic at this stage. We shall see in the next section that
it marked a departure from de Moivre's model to a more realistic one. For de 
Moivre's law of mortality, it is easy to confirm that
\begin{eqnarray}
{}_np_x &=& \frac{\omega - (x + n)}{\omega - x} \label{s1e6} \\
{}_nq_x &=& \frac{n}{\omega - x} \label{s1e7} \\
\mu(x) &=& \frac{1}{\omega - x} \label{s1e8}
\end{eqnarray}
de Moivre himself did not consider his law to be an accurate description of
human mortality. He emphasized in his treatise that it was an approximation
useful to calculate the annuities. His piecewise linear approximation was a
valuable device to carry out practical computations in the eighteenth century.

\section{Gompertz's law}\label{s2}
An immediate consequence of de Moivre's law is that an individual's resistance
to death diminishes algebraically as time goes by. The English actuary 
Benjamin Gompertz observed \cite{gompertz1825xxiv} that the resistance to 
death decreases geometrically instead. If one considers small enough time 
intervals then at the end of every interval a person's resistance to death 
reduces by the same proportion. Expressed mathematically, it means that
\begin{equation}\label{s2e1}
\frac{d\nu}{dx} = -k\nu(x),
\end{equation}
where the function $\nu$ was defined in equation \eqref{s1e5}. It immediately
follows that
\begin{equation}\label{s2e2}
\log\nu(x) = -kx + \log B,
\end{equation}
where $B$ is a constant of integration. The `force of mortality' or the
hazard function is therefore
\begin{equation}\label{s2e3}
\mu(x) = Be^{kx}.
\end{equation}
The constant $B$ is called baseline mortality and $k$ is called the 
senescent component.
An individual's susceptibility to die thus increases exponentially with age.
From equation \eqref{s1e4} and \eqref{s2e3}, the differential equation for
the survival function is
\begin{equation}\label{s2e4}
\frac{s^\prime(x)}{s(x)} = Be^{kx}.
\end{equation}
The solution of this ordinary differential equation is
\begin{equation}\label{s2e5}
s(x) = C\exp\left(\frac{B}{k}\exp(kx)\right),
\end{equation}
where $C$ is another constant of integration. The constants $B$ and $C$ in
equation \eqref{s2e5} are determined from the mortality data of the population
under study. Gompertz suggested that his formula is applicable for the age
group between $10-15$ years of age up to $55-60$. In order to extend it beyond
the age of $60$, Gompertz recommended that a different set of constants $B$
and $C$ be used.

Gompertz was aware that death in a population has at least two factors. One
of them is the deterioration in the individual's resistance to death. The 
other one is chance alone. The first factor depends on the individual's age
while the second factor is constant throughout. However, in the formulation
of his law of mortality, Gompertz considered only the first factor.

\section{Makeham's law and its generalisations}\label{s3}
William Makeham, the English mathematician and actuary, added a term to
Gompertz's law of resistance to death which the latter had acknowledged but
not included. Makeham's modification \cite{makeham1867law} of equation 
\eqref{s2e3} is
\begin{equation}\label{s3e1}
\mu(x) = A + Be^{kx},
\end{equation}
where $A$ is a constant independent of the person's age. Makeham's survival
function is
\begin{equation}\label{s3e2}
s(x) = C\exp\left(Ax + \frac{B}{k}\exp(kx)\right).
\end{equation}
Makeham's survival function has three constants $A, B$ and $C$ and therefore
can be fitted to emprically observed mortality data more effectively than
Gompertz's model. Makeham's law was often applied to mortality tables in the
age range beyond $20$ years to almost end of life\cite{jordan1967society}. 
In 1890\cite{makeham1890further}, Makeham proposed yet another modification to 
his law by adding a linear term to the hazard function or the force of 
mortality. Makeham thought that in addition to the two factors spotted by
Gompertz there is another one that grows linearly with age. It was proposed to 
be
\begin{equation}\label{s3e3}
\mu(x) = A_1 + A_2x + Be^{kx}.
\end{equation}
The resulting survival function is
\begin{equation}\label{s3e4}
s(x) = C\exp\left(A_1x + \frac{A_2}{2}x^2 + \frac{B}{k}\exp(kx)\right).
\end{equation}
Makeham's law, like its predecessor, Gompertz's law was used to construct
mortality tables of adults. Their simplicity allowed them to be used 
effectively up to as late as the 1940s. Gompertz law was used to construct
the 1937 Standard Annuity Table and Makeham's law for 1940 Annuity table
\cite{jordan1967society}. Both laws assumed that the force of mortality 
increases monotonically with time. However, it is commonly observed that 
infant mortality contradicts this assumption. In order to extend Makeham's
law of 1860 to infantile ages, Wilhem Lazarus \cite{lazarus1867ueber} added
an exponentially decreasing term. His law expressed the force of mortality
as 
\begin{equation}\label{s3e5}
\mu(x) = B_1 e^{-k_1x} + A + B_2e^{k_2 x}.
\end{equation}
The constants $B_1$ and $B_2$ are positive numbers. The corresponding survival 
function is
\begin{equation}\label{s3e6}
s(x) = 
C\exp\left(-\frac{B_1}{k_1}e^{-k_1x} + Ax + \frac{B_2}{k_2}e^{k_2x}\right)
\end{equation}

The way infants' susceptibility to die of diseases upsets Gompertz's and 
Makeham's assumption of monotonicity of the law of mortality, do does the 
spike in the death rate of young adults. Wars were frequent in Europe of the 
eighteenth century and the victims were disproportionately the young recruits.
Even otherwise, young adults are more prone to death by accidents. In order
to take into account this mortality hump in the young, Thiele 
\cite{thiele1871mathematical} introduced a gaussian term to Lazarus' model.
His law of mortality is
\begin{equation}\label{s3e7}
\mu(x) = B_1 e^{-k_1x} + Ae^{-a_1(x - a_2)^2} + B_2e^{k_2 x}.
\end{equation}
All the constants in this equation, namely $A, a_1, a_2, B_1, k_1, B_2$ and 
$k_2$ are positive numbers. The presence of the gaussian term prevents us
from writing a closed form expression of the survival function. However, the
ordinary differential equation for the survival function can be readily 
integrated numerically. Alternatively, if the initial conditions are available,
one can write its solution in terms of the error function.

We observe that all generalisations of Makeham's laws introduce additional
constants to the force of mortality and the hazard function. These constants
provide additional `degrees of freedom' to the functions used to fit the 
mortality data, resulting in a better fit.

Forfar, McCutcheon and Wilkie proposed a far wider generalisation of the
Gompertz and Makeham's laws. They defined a class of models, called GM models
after their inventors, with the mathematical form
\begin{equation}\label{s3e8}
\mu(x) = \sum_{i=0}^{r-1}\alpha_i x^i + 
\exp\left(\sum_{i=1}^{s-1}\beta_i x^i\right).
\end{equation}
They also used the convention that if $r = 0$ then the polynomial terms are 
absent and if $s = 0$ then the exponential terms do not appear. They called
the law of force of mortality of equation \eqref{s3e8} as $\mathrm{GM}(r,s)$.
It is easy to check that Gompertz's law is $\mathrm{GM}(0, 2)$, Makeham's
first law is $\mathrm{GM}(1,2)$ and Makeham's second law is $\mathrm{GM}(2,2)$.
The $\mathrm{GM}(0, 2)$, $\mathrm{GM}(2,2)$ and $\mathrm{GM}(1,3)$ are used
by the Continuous Mortality Investigation Bureau\cite{pitacco2016high} in the 
United Kingdom.

\section{Other mortality laws prior to the 20th century}\label{s4}
de Moivre's, Gompertz's and Makeham's laws of mortality were not the only
ones in vogue in the nineteenth century and prior to it. In this section we
mention a few notable ones without commenting on their merits. Lambert's
survival function \cite{lambert1776dottrina} was
\begin{equation}\label{s4e1}
s(x) = \left(\frac{a - x}{x}\right)^2 - b\left(e^{-x/c} - e^{-x/d}\right).
\end{equation}
It had four degrees of freedom. Babbage\cite{babbage1823tables} proposed a 
quadratic survival function
\begin{equation}\label{s4e2}
s(x) = c - bx - ax^2.
\end{equation}
Young proposed a polynomial of degree $40$ as the survival function in 
\cite{adler1866memoir} 1826. von Littrow\cite{von1832lebensversicherungen}
extended Babbage's model to polynomials of higher degree. Moser
\cite{moser1839gesetze} proposed a polynomial survival function with 
fractional powers of $x$. It has five degrees of freedom and had the form
\begin{equation}\label{s4e3}
s(x) = 1 - ax^{1/4} + bx^{9/4} - cx^{17/4} - dx^{25/4} + ex^{33/4}.
\end{equation}
All these models were attempts to fit the mortality data with a continuous 
function. They were not rooted in demographic observations like the models
of Gompertz, Makeham, Lazarus or Thiele. As a result, they soon fell into
disuse after Gompertz proposed his model and others improved upon it.

\section{Heligman-Pollard model}\label{s5}
The term `odds' is a well-defined term in probability theory. When we are 
dealing with an experiment with two outcomes - that something happens or 
it does not - then it is common in certain fields to express the 
probabilities in terms of odds.  For example, if $p$ is the probability 
that an event will happen and $q = 1 - p$ is the probability that it will 
not happen then the odds of the experiment is $p/q$. 

Recall from equations \eqref{s1e2} and \eqref{s1e3} that $p_x$ is the 
probability that life aged $x$ will survive for another year and $q_x$ is
the probability of the complimentary event. Therefore, the odds of death in 
this case are $q_x/p_x$.  Heligman and Pollard \cite{heligman1980age} proposed 
a model that has the algebraic structure of Thiele's mortality law but 
applied to odds of survival. Mathematically it is expressed as
\begin{equation}\label{s5e1}
\frac{q_x}{p_x} = A^{(x+B)^C}+
D\exp\left(-E\log^2\left(\frac{x}{F}\right)\right) + GH^x.
\end{equation}
The model has eight parameters, $A, B, C, D, E, F, G$ and $H$. Of these, $A,
B, C, D \in (0, 1)$, $E > 0$, $F \in (15, \omega)$, $G \in (0, 1)$ and $H
> 0$. The constant $\omega$ is the hump maximum and it can be between $55$
and $100$. The Heligman-Pollard model was first developed for the Australian
population post the second world war. An advantage of Heligman-Pollard model 
is in biological interpretation of each of the three terms on the right hand 
side of equation \eqref{s5e1}.

The first term on the right hand side of equation \eqref{s5e1} represent 
infantile mortality. It is a fast declining exponential representing the 
rapid fall in mortality during infancy. $A$ is approximately equal to $q_1$ 
and is a measure of the mortality rate of a one year old child. $C$ is a 
measure of how quickly the new-born adjusts to its surroundings and gains 
immunity. A higher $C$ indicates the fast decline in infant mortality as the
child passes through infancy. When $B = 0$, $q_0 = 0.5$ irrespective of the
values taken by $A$ and $C$. The value of $q_0$ is closer to $q_1$ if $B$ is
higher for a given value of $C$. $B$ is thus an indicator of the central 
tendancy of infant mortality. 

The second term is gaussian in the logarithm of age. It represent the accident
mortality for young adults of both sexes and maternal mortality in young 
females. It covers the `accident hump` observed in all demographic data. It
is prominently observed between ages $10$ and $40$. The parameter $D$ controls 
the severity of accident hump, $E$ determines the spread of the hump and $F$ 
the location.  Using a statistical analogy, $E$ is a measure of spread and 
$F$ that of the central tendency. 

The third term traces its roots to the Gompertz model. It represents the
exponential increase in the deterioration of the body. The parameter $G$ 
represents the senescent mortality and $H$ the increase in the rate of that
process.

\section{Lee-Carter model}\label{s6}
The problem of forecasting population changes and composition is of interest
to both the demographers and the pension fund managers. Ronald Lee and 
Lawrence Carter's motivation for developing a model to forecast mortality was
the observation that the human life expectancy rose from $47$ years to $75$ 
years in the United States in the $88$ years starting from the year $1900$.
Should this trend continue unabated in the future, the human life expectancy
will touch $100$ years by the year $2065$ upsetting the Social Security 
Administration's calculations based on the long-term life expectancy of about
$80.5$ years. The wide difference between Lee and Carter's 
\cite{lee1992modeling} forecasts and the assumptions of the pension funds 
made the actuaries turn their attention to forecasting than modelling alone.

Unlike the previous models which tried to build formulae that mimicked the
behaviour of human mortality in various stages of life, Lee and Carter used
the statistical techniques of time series for their projection into the future.
They excluded factors representing advancement in medicine or the behavioural
and social changes on mortality. Their time series model extrapolated the 
long-term trends seen in demographic data over several decades. They did not
find it necessary to assume that the human life cannot extend beyond a certain
limit. Nothing analogous to the $\omega$ in de Moivre's model would be found
in Lee and Carter's.

The mathematical form of Lee and Carter's model is
\begin{equation}\label{s6e1}
\log{M}(x, t) = {a}_x + {b}_x{k}_t + \epsilon_{x, t},
\end{equation}
where the coefficients ${a}_x$ and ${b}_x$ depend on the age, the
`index' ${k}_t$ depends on time and ${M}(x, t)$ is the mean death
rate for age $x$ in time $t$. Since
\[
\frac{d}{dt}{M}(x, t) = {b}_x\frac{dk_t}{dt},
\]
${b}_x$ captures the the changes in mortality rates due to changes in
the index with time. A positive value of a component of ${b}_x$ indicates
falling mortality while a negative value indicates the opposite. The term
$\epsilon_{x, t}$ is an `error term' with mean $0$ and variance that depends
on the age. It captures the factors that influence mortality but are not
explicitly included in the model.

The model of equation \eqref{s6e1} does not have a unique solution. If 
${a}$, ${b}$ and ${k}$ form one solution then for any number $c$,
the triple ${a} - c{b}, {b}, {k} + c$ is also a solution. In
fact, even ${a}, c{b}, {k}/c$ is a solution if $c \ne 0$. This phenomenon is
also called `identifiability problem'\cite{plat2009stochastic}.

Fitting the Lee-Carter model consists in finding the parameters ${a}_x,
{b}_x$ and ${k}_t$ for a given matrix of mortality rates ${M}(x, t)$.
The model is solved using the singular value decomposition (SVD). The algorithm
is described in appendix A to Lee and Carter's paper\cite{lee1992modeling} 
introducing the model.

Lee and Carter's forecast of life expectancy for the American population was 
$86.05$ by the year $2065$. The Actuary of the Social Security Administration,
on the other hand, forecast it as $80.5$. In $2020$ the observed value is 
$78.87$, suggesting that Lee and Carter's forecast might be closer to the 
reality in the year $2065$.

The advantages of Lee-Carter model lie in its robustness, simplicity and 
the fact that it fits well over wide ranges of age. It is also observed to be
able to fit small non-linearities in the mortality curve quite well. Its 
shortcomings are its lack of smoothness of age effects in small populations, 
inability to work with cohorts, inability to cope with improvements varying 
across times and a possible underestimation of uncertainty. It also has a 
limited versatality owing to it being a one-factor model.

\section{Age-Period-Cohort models}\label{s7}
Demographic data is often analysed by taking into account the age, period 
and the cohort of individuals. The analysis need not be for mortality alone.
It could be for incidence of diseases or even economic consumption. Consumption
patterns do depend on age of the individual. But when they are observed over
a long enough duration they are also found to depend on the period and the 
cohort. For instance, certain goods may not have been available or would have
been expensive in a certain period and therefore we not consumed by many. It
is also well-known that different age groups of people have different tastes.
The age-period-cohort (APC) models are a class of additive models where the
predictor is a sum of three time effects, age, period and cohort. APC models
are thus able to take into account the impact of the changes in the society 
and the available technology.

Period analysis alone is quite useful to understanding the effect of wars,
pandemics, revolutions or other upheavals on a population. However, they
capture the effect of the times in which people are living. Behavioural
changes in people are better captured by considering cohorts. The 
characteristics of a cohort are an aggregate of the characteristics of its 
members\cite{willekens1991age}. Modern APC models require longitudnal data
to understand the life processes as they evolve. They do not consider just
the event of the death of an individual but the process of dying whose 
culmination is death. They take the view that the mortality risks in a 
population are better determined by an understanding of morbidity in it
\cite{van1990determinants}.

The APC framework is used widely in the social sciences. In the context of
mortality modelling and forecasting it started being used while answering the
questions \cite{willekens1991age}:
\begin{itemize}
\item Does mortality show a greater regularity when viewed at the level of a
cohort or for a particular period? The answer to this question is important
for mortality forecasting.

Although a full-fledged APC framework arose relatively recently, the importance
of cohort analysis was not missed by early demographers and actuaries. Derrick
\cite{derrick1927observations} observed in 1927 that the ratio of mortality
for one cohort to that of another was constant for all ages above $10$ years.
It suggested that it may be possible to forecast the mortality of an individual
based on the cohort in which he falls. It was also observed that the mortality
rates for the generation that was young during the years of the second world
war were overestimated for obvious reasons. This once again indicates the 
importance and the role of cohorts in modelling mortality. 

\item Do events early in life affect the experiences later in life? This 
question can be answered only in the context of a cohort analysis.

While studing the death rates in England, Scotland and Sweden, Kermack
\cite{kermack1934death} observed that the differences in mortality was mostly
because of the environmental conditions experienced in the first fifteen years
of life. It was not a result of the other influences in later life. The 
study also uncovered the fact that an improvement in the conditions around
child-birth boosted survival rates of new-borns. It proposed that the health
of the mother has a positive impact on the health of the child and its chances
to live longer. Preston and de Walle \cite{preston1978urban} came to similar
conclusion for the French mortality data. This idea was further supported by 
Caselli and Capocaccia's study\cite{caselli1989age} on Italian demographics 
that infant mortality had a weakening effect on eventual mortality. However, 
this observation is not universally accepted. Other studies indicate that a 
high infantile mortality results in lower eventual mortality because the 
`stronger' individuals stay long enough to live long enough 
\cite{manton1981methods}. Lest one concludes that only childhood environment
determines mortality rate later in life, Horiuchi reported 
\cite{horiuchi1983long} that the malnutrition and physical privation during the
second world war wreaked the health of those who lived through it and affected
their mortality when they became old.
\end{itemize}

APC studies are plagued by what is called the `identification problem' common
to all cohort analysis. It is the problem of assigning an individual to the
right cohort when the a) the cohorts are adjacent in time, b) the individual 
is on the border line of two adjacent cohorts and c) the characteristics of
the cohorts are quite distinct. The problem can be mitigated by following
the directions suggested in Willekens and Scherbov's \cite{willekens1991age}
analysis.

APC model can be expressed as a generalized linear model in which we predict
the mortality rate from age, period and cohort as predictors. We usually use
the variables in the data that are the most appropriate proxy for age, period
and cohort. Once the model is build from the available data, we can use it to 
forecast mortality for a newer set of predictors. It is assumed that the 
mortality rate can be described as a Poisson process. This assumption is found 
to be valid for societies with low death rates. It may not hold good when 
the society is experiencing a war or a pandemic.


\section{Cairns-Blake-Dowd model}\label{s8}
Cairns, Blake and Dowd proposed a model \cite{cairns2006two} to study the
evolution of mortality beyond sixty years of age and its impact on longevity
risk. It was a two factor stochastic model. Of these, the first factor affects
the mortality rate at all ages in an identical manner and the second one 
affects the advanced years to a greater extent. Their mortality curve is
defined in terms of forward survival probability $\pr(t, T_0, T_1, x)$. It is
the probability measured at $t$ that an individual aged $x$ at time $0$,
alive at $T_0$ will survive until time $T_1 > T_0$. The curve is represented
by the equation
\begin{equation}\label{s8e1}
1 - p(t+1,t,t+1,x) = 
\frac{e^{A_1(t+1)+A_2(t+1)(x+t)}}{1+e^{A_1(t+1)+A_2(t+1)(x+t)}},
\end{equation}
where $A_1(u)$ and $A_2(u)$ are stochastic processes. If $q(p, T_0, T_1, x)
= 1 - p(t, T_0, T_1, x)$ then we can readily write equation \eqref{s8e1} in
the form
\begin{equation}\label{s8e2}
\log\left(\frac{q(t,T_0,T_1,x)}{p(t,T_0,T_1,x)}\right) = 
A_1(t+1) + A_2(t+1)(x+t).
\end{equation}
The log-odds of probability of death is thus a linear function of age and the
coefficients of this relation vary with time. The model uses data from 
different cohorts at a common point in time. Therefore, the coefficients 
$A_1(t)$ and $A_2(t)$ are interpreted as factors. The original model of Cairns,
Blake and Dowd used ordinary least square regression to estimate the factors.
The authors plotted the trend of the factors for the period between $1961$ and
$2002$. The factor $A_1(t)$ decreases with time indicating an improvement in
the mortality. On the other hand, $A_2(t)$ is observed to increase with time.
This suggests that the improvements in mortality are felt to a lesser extent 
for older people. In order to forecast the factors at times in future, the 
authors model $A(t) = (A_1(t), A_2(t))^T$ as a random walk with a drift. That
is,
\begin{equation}\label{s8e3}
A(t+1) - A(t) = \mu + CZ(t+1),
\end{equation}
where $\mu$ is a constant vector representing the mean increment, $C$ is a 
constant $2 \times 2$ upper triangular matrix and $Z(t)$ is a standardised
two dimensional gaussian random variable. The authors also propose a criterion
for a good model of this kind. They introduce the idea of `biological 
reasonability'. In general, a biologically reasonable model will have the 
first component of $\mu$ negative and the second component positive. Further,
the mortality rates for older cohorts should normally be greater than the 
younger cohorts.

Practitioners favour Cairns-Blake-Dowd model for its robustness and the ease
with which it allows inclusion of parameter uncertainty. It is also more 
versatile than the Lee-Carter model because it has an additional factor. 
However, like the Lee-Carter model it does not allow analysis of cohort effects.
Although it models a wide range of advanced years, it does not fit the 
mortality data as well as Lee-Carter model.

\section{Stochastic cohort models}\label{s9}
The stochastic models of Lee-Carter and Cairns-Blake-Dowd were unable to
incorporate cohort effects. To remedy this shortcoming, Renshaw and Haberman
\cite{renshaw2006cohort} proposed a modification of the Lee-Carter model that 
includes cohorts. It can be expressed mathematically as
\begin{equation}\label{s9e1}
\log{M}(x, t) = {a}_x + {b}_x{k}_t + {c}_x\gamma_{t-x},
\end{equation}
where the symbols have the same meaning as in Lee-Carter model. In the new
term, third on the right hand side, $\gamma_{t-x}$ captures the cohort effect.
It is a function of $t - x$, the (approximate) year of birth and ${c}_x$
is just the regression coefficient of this term. Although the model fitted the
male mortality data in England and Wales quite well it turned to not as 
robust as other models. The lack of robustness is believed to be related to
the shape of the likelihood function. It has more than one local maximum.
Therefore, when we change the age or the year range the optimizer ends up
settling on a different maximum each time\cite{cairns2008modelling}. Currie
simplified the Renshaw-Haberman model to
\begin{equation}\label{s9e2}
\log{M}(x, t) = {a}_x + {k}_t + \gamma_{t-x}.
\end{equation}
The simplification solved the problem of robustness but made the fit poorer
\cite{plat2009stochastic}. Plat introduced a model to address the deficiencies
of all the previous models while retaining their benefits 
\cite{plat2009stochastic}. Its mathematical structure is
\begin{equation}\label{s9e3}
\log M(x,t) = a_x + \kappa^1_t + \kappa^2_t(\bar{x} - x) + 
\kappa^3_t(\bar{x} - x)^+ + \gamma_{t-x},
\end{equation}
where $(\bar{x} - x)^+ = \max(\bar{x} - x, 0)$ and $\bar{x}$ is the mean age
in the sample range. The term $a_x$ plays a 
similar role as it did in Lee-Carter model. It controls the general shape
of the mortality curvve. Of the four stochastic factors, $\kappa_t^1$
represents the change in the level of mortality across all ages, $\kappa_t^2$
represents the change in the level of mortality between ages, $\kappa_t^3$
captures the differences in mortality behaviour in the early adulthood stage
and $\gamma_{t-x}$ captures the cohort effect. If one is interested in 
modelling only the advanced ages then one need not worry about the `accident
hump' of young adulthood and use the simplified model,
\begin{equation}\label{s9e4}
\log M(x,t) = a_x + \kappa^1_t + \kappa^2_t(\bar{x} - x) + \gamma_{t-x},
\end{equation}
Like the Lee-Carter model, this one too suffers from the `identifiability
problem'. For constants $c_1, c_2, d$, the set of parameters
\begin{eqnarray*}
\bar{\gamma}_{t-x} &=& \gamma_{t-x} + c_1 + c_2(t - x) \\
\bar{\kappa}_t^1 &=& \kappa^1_t + c_1 - d\bar{x}c_2 \\
\bar{\kappa}_t^2 &=& \kappa^2_t + dc_2 \\
\bar{a}_x &=& a_x + (1 - d)c_2
\end{eqnarray*}
also lead the the same values for $\log M(x, t)$. The problem is mitigated 
by requiring that 
\begin{eqnarray*}
\sum_{i=x_0}^{x_1} \gamma_i &=& 0 \\
\sum_{i=x_0}^{x_1} i\gamma_i &=& 0 \\
\sum_t\kappa_t^3 &=& 0,
\end{eqnarray*}
where $x_0$ and $x_1$ are the earliest and the latest years of birth to which
the cohort effect is fitted. 
\bibliography{draft}
\bibliographystyle{plain}
\end{document}

