\chapter{Functions on Euclidean Space}\label{c1}
\section{Norm and inner product}\label{c1s1}
$\sor^n$ has points $x = (x^1, \ldots, x^n)$ such that if $\alpha \in \sor$
then $\alpha x = (\alpha x^1, \ldots, \alpha x^n)$ is also a point in $\sor^n$
and so is $x + y = (x^1 + y^1, \ldots x^n + y^n)$. $\sor^n$ is a linear vector
space. 
\begin{defn}\label{c1s1d1}
The norm of a vector $x \in \sor^n$ is defined as
\[
\norm{x} = \left((x^1)^2 + \cdots + (x^n)^2\right)^{1/2}.
\]
\end{defn}

\begin{defn}\label{c1s1d2}
The inner product of vectors $x, y \in \sor$ is defined as
\[
\ip{x}{y} = \abs{\sum_{i=1}^n x^i y^i }.
\]
\end{defn}

\begin{lem}\label{c1s1l1}
$\norm{x}^2 = \ip{x}{x}$.
\end{lem}

\begin{lem}\label{c1s1l2}
$\ip{x}{y} = \ip{y}{x}$.
\end{lem}

\begin{lem}\label{c1s1l3}
$\ip{\alpha x}{y} = \alpha\ip{y}{x}$ and $\ip{x}{\alpha y} = \alpha\ip{x}{y}$
for all $\alpha \in \sor$.
\end{lem}

\begin{lem}\label{c1s1l4}
$\ip{x}{y_1 + y_2} = \ip{x}{y_1} + \ip{x}{y_2}$ and $\ip{x_1 + x_2}{y} = 
\ip{x_1}{y} + \ip{x_2}{y}$.
\end{lem}

\begin{lem}[Polarisation identity]\label{c1s1l5}
\[
\ip{x}{y} = \frac{\norm{x + y}^2 - \norm{x - y}^2}{4}.
\]
\end{lem}
\begin{proof}
Follows immediately from lemmas \ref{c1s1l1} and \ref{c1s1l2}.
\end{proof}

\begin{lem}\label{c1s1l6}
$\norm{x} = \norm{-x}$.
\end{lem}

The norm has the following properties.
\begin{thm}\label{c1s1t1}
If $x, y \in \sor^n$ and $\alpha \in \sor$ then
\begin{enumerate}
\item $\norm{x} \ge 0$ and $\norm{x} = 0$ iff $x = 0$.
\item Cauchy-Schwarz inequality
\[
\ip{x}{y} \le \norm{x}\norm{y}.
\]
the equality is true if $x = \lambda y$ for some $\lambda \in \sor$.
\item $\norm{x + y} \le \norm{x} + \norm{y}$.
\item $\norm{\alpha x} = \abs{\alpha}\norm{x}$ for all $\alpha \in \sor$.
\end{enumerate}
\end{thm}
\begin{proof}
$\norm{x}$ is the positive square root of the sum of non-negative reals. 
Therefore it is non-negative. If $x = 0$ then clearly $\norm{x} = 0$. If
$\norm{x} = 0$ then the sum of $n$ non-negative numbers is zero, which is
possible only if all of them are zero.

Consider $\norm{x - \lambda y}^2 = \ip{x - \lambda y}{x - \lambda y}$
so that
\[
\norm{x - \lambda y}^2 = \ip{x}{x} - 2\lambda\ip{x}{y}  + \lambda^2\ip{y}{y}
\]
We showed previously that $\norm{x - \lambda y} \ge 0$ and that it is zero
iff $x - \lambda y = 0$. If $\norm{x - \lambda y}^2 > 0$ then then the quadratic
on the rhs has no real roots, in which case the discriminant
\[
4\lambda^2\ip{x}{y}^2 - 4\lambda^2\norm{x}^2\norm{y}^2 < 0
\]
from which it follows that
\[
\ip{x}{y} < {\norm{x}}{\norm{y}}.
\]
If, on the other hand, $\norm{x - \lambda y} = 0$ then the quadratic has real
roots in which case $\ip{x}{y} \ge {\norm{x}}{\norm{y}}$. However, if $\norm{x -
\lambda y} = 0$ then $x = \lambda y$ and then $\ip{x}{y} = {\norm{x}}
{\norm{y}}$. In either case, $\ip{x}{y} \le {\norm{x}} {\norm{y}}$. Now suppose
that $\ip{x}{y} = \norm{x}\norm{y}$ then the discriminant of the quadratic
is zero which indicates that real roots exist and that $x = \lambda y$.

$\norm{x + y}^2 = \ip{x+y}{x+y} = \norm{x}^2 + 2\ip{x}{y} + \norm{y}^2$. Using
the Cauchy-Schwarz inequality, $\norm{x + y}^2 \le \norm{x}^2 + 2\norm{x}
\norm{y} + \norm{y}^2 = (\norm{x} + \norm{y})^2$.

The fourth statement follows immediately from the definitions of the scalar
product and the norm.
\end{proof}

\subsection{Problems}
\begin{enumerate}
\item We will prove by induction on $n$. If $n = 1$, $x = (x^1)$ and $\norm{x}
= \sqrt{(x^1)^2} \le \abs{x^1}$, as we always choose the positive square root.
Assume that the statement is true for all $n < k$ and consider
\[
\norm{x}^2 = \sum_{i=1}^{k-1}(x^i)^2 + (x^k)^2 \le 
\left(\sum_{i=1}^{k-1}\abs{x^i}\right)^2 + \abs{x^k}^2 = 
\left(\sum_{i=1}^k\abs{x^i}^2\right)^2.
\]

\item When is $\norm{x + y} = \norm{x} + \norm{y}$? Only when $x = \lambda y$ 
for $\lambda \ge 0$.

\item $\norm{x - y} = \norm{x + (-y)} \le \norm{x} + \norm{-y} = \norm{x} + 
\norm{y}$. Equality holds when $x = \lambda y$ with $\lambda \le 0$.

\item $\norm{x} = \norm{x - y + y} \le \norm{x - y} + \norm{y}$ so that
$\norm{x} - \norm{y} \le \norm{x - y}$. We can similarly show that $\norm{y} -
\norm{x} \le \norm{y - x} = \norm{x - y}$.

\item The length of one side of a triangle never exceeds the sum of lengths of
the other two sides.

\item Given that $f$ and $g$ are (real-valued) integrable on $[a, b]$. 
\begin{enumerate}
\item[(a)] Then
\[
\int_a^b (f - \lambda g)^2 = \int_a^b f^2 - 2\lambda\int_a^b fg + \lambda^2
\int_a^b g^2.
\]
The expression is non-negative. If suppose it is zero then $f - \lambda g = 0$
almost everywhere. If $f$ and $g$ are continuous then $f = \lambda g$, that is
the two functions are linearly dependent, in which case
\[
\int_a^b fg = \left(\int_a^b f^2\right)^{1/2}\left(\int_a^b g^2\right)^{1/2}.
\]
On the other hand, if the expression
is positive then the quadratic
\[
\lambda^2 \int_a^b g^2 - 2\lambda\int_a^b fg + \int_a^b f^2
\]
has no real roots, which is possible only when the discriminant
\[
4\lambda^2 \left(\int_a^b fg\right)^2 - 
4\lambda^2\left(\int_a^b f^2\right)\left(\int_a^b g^2\right) < 0
\]

\item[(b)] In the case of equality, $f = \lambda g$ only if both functions are
continuous. Otherwise, $f = \lambda g$ a.e. and the two are \emph{not} linearly
dependent.

\item[(c)] Part 2 of theorem \ref{c1s1t1} is a special case of this statement
because a norm defined as a sum has properties similar to an integral except
that when the norm is zero the vector is also zero.
\end{enumerate}

\item
\begin{enumerate}
\item[(a)] If $T$ is inner product preserving then $\ip{T(x)}{T(y)}=\ip{x}{y}$.
Choose $x = y$. Then $\ip{T(x)}{T(x)} = \ip{x}{y} \Rightarrow \norm{T(x)}^2 =
\norm{x}^2$ or that $T$ is norm preserving.

To prove the converse, use the polarisation identity (lemma \ref{c1s1l5})
\[
\ip{T(x)}{T(y)} = \frac{\norm{T(x) + T(y)}^2 - \norm{T(x) - T(y)}^2}{4}.
\]
Since $T$ is linear, $T(x \pm y) = T(x) \pm T(y)$ so that
is inner product preserving as well.
\[
\ip{T(x)}{T(y)} = \frac{\norm{T(x + y)}^2 - \norm{T(x - y)}^2}{4}.
\]
Since $T$ is norm preserving,
\[
\ip{T(x)}{T(y)} = \frac{\norm{x + y}^2 - \norm{x - y}^2}{4} = \ip{x}{y}.
\]

\begin{rem}
Every inner product preserving transformation is a norm-preserving 
transformation but the converse is true only if the transformation is linear.
The set of norm preserving transformations is, in general, bigger than the
set of inner-product preserving transformations.
\end{rem}

\item[(b)] Let $T$ be a norm-preserving linear transformation and let if 
possible $T(x_1) = T(x_2)$. Then $0 = \norm{T(x_1) - T(x_2)} = 
\norm{T(x_1 - x_2)} = \norm{x_1 - x_2}$ which implies that $x_1 = x_2$.

Thus, $T(e_i) \ne T(e_j)$ for all $i \ne j$ and $T$ is also onto. As a result,
$T^{-1}$ exists. To show that $T^{-1}$ is of the same sort, it suffices to show
that $T^{-1}$ is linear and norm preserving. To show that it is linear, let
$T(x_1) = y_1, T(x_2) = y_2$ and consider
\[
T^{-1}(y_1 + y_2) = T^{-1}(T(x_1) + T(x_2)).
\]
Since $T$ is linear, the right hand side is $T^{-1}(T(x_1 + x_2)) = x_1 + x_2
= T^{-1}(y_1) + T^{-1}(y_2)$. Similarly, $T^{-1}(cy_1) = T^{-1}(cT(x_1)) = 
T^{-1}T(cx_1) = cx_1 = cT^{-1}(y_1)$. To show that it is norm-preserving,
consider $\norm{T^{-1}(y_1)} = \norm{T^{-1}T(x_1)} = \norm{x_1}$. But $T$ is
norm-preserving so that we have $\norm{T^{-1}(y_1)}=\norm{T(x_1)}=\norm{y_1}$,
making $T^{-1}$ norm-preserving.
\end{enumerate}

\item 
\begin{enumerate}
\item[(a)] If $T$ is norm preserving then it is also inner-product preserving.
Therefore, it leaves the quantity
\[
\frac{\ip{x}{y}}{\norm{x}\norm{y}}
\]
invariant. 

\item[(b)] There is a mistake in the problem statement. $T$ is angle preserving
if $\lambda_1 = \ldots = \lambda_n = \lambda$. In this case, let
\begin{eqnarray*}
a &=& \alpha_1 x_1 + \cdots + \alpha_n x_n \\
b &=& \beta_1 x_1 + \cdots + \beta_n x_n 
\end{eqnarray*}
Then
\begin{eqnarray*}
\norm{a}^2 &=& \ip{a}{a} = \sum_{i,j=1}^n\alpha_i\alpha_j\ip{x_i}{x_j} \\
\norm{b}^2 &=& \ip{b}{b} = \sum_{i,j=1}^n\beta_i\beta_j\ip{x_i}{x_j} \\
\ip{a}{b} &=& \sum_{i,j=1}^n\alpha_i\beta_j\ip{x_i}{x_j}
\end{eqnarray*}
and
\begin{eqnarray*}
\norm{T(a)}^2 = \sum_{i,j=1}^n\lambda^2\alpha_i\alpha_j\ip{x_i}{x_j} \\
\norm{T(b)}^2 = \sum_{i,j=1}^n\lambda^2\beta_i\beta_j\ip{x_i}{x_j} \\
\ip{T(a)}{T(b)} = \sum_{i,j=1}^n\lambda^2\alpha_i\beta_j\ip{x_i}{x_j}
\end{eqnarray*}
so that
\[
\angle(T(a),T(b)) = \angle(a, b).
\]

To spot this mistake, consider the $2$-dimensional case with $T(x_1) = x_1,
T(x_2) = -x_2$.

Let us now examine the converse. Let $T(x_i) = \lambda_i x_i$. Introduce the
variables
\begin{eqnarray*}
A_{ij} &=& \alpha_i\alpha_j\ip{x_i}{x_j} \\
B_{ij} &=& \beta_i\beta_j\ip{x_i}{x_j} \\
C_{ij} &=& \alpha_i\beta_j\ip{x_i}{x_j}
\end{eqnarray*}
so that
\begin{eqnarray*}
\angle(a, b) &=& \frac{\sum_{r,s}C_{rs}}
                 {\sqrt{\sum_{k,l}A_{kl}}\sqrt{\sum_{m,n}B_{mn}}} \\
(\angle(a, b))^2 &=& \frac{\sum_{rstu}C_{rs}C_{tu}}
                 {\sum_{k,l}A_{kl}\sum_{m,n}B_{mn}}  \\
(\angle(T(a), T(b)))^2 &=& \frac{\sum_{rstu}\lambda_r\lambda_s\lambda_t\lambda_u
    C_{rs}C_{tu}}
    {\sum_{k,l}\lambda_k\lambda_l A_{kl}\sum_{m,n}\lambda_m\lambda_n B_{mn}} 
\end{eqnarray*}
When $T$ is angle preserving,
\[
\sum_{k,l,m,n,r,s,t,u}\lambda_k\lambda_l\lambda_m\lambda_n A_{kl}B_{mn}C_{rs}
C_{tu} = 
\sum_{k,l,m,n,r,s,t,u}\lambda_r\lambda_s\lambda_t\lambda_u A_{kl}B_{mn}C_{rs}
C_{tu}
\]
or
\[
\sum_{k,l,m,n,r,s,t,u}(\lambda_k\lambda_l\lambda_m\lambda_n - 
\lambda_r\lambda_s\lambda_t\lambda_u)A_{kl}B_{mn}C_{rs}C_{tu} = 0.
\]
This equation is true for all vectors $a, b$, that is all possible values of 
$A_{kl}, B_{mn}, C_{rs}$ and $C_{tu}$. Therefore, we must have
\[
\lambda_k\lambda_l\lambda_m\lambda_n = \lambda_r\lambda_s\lambda_t\lambda_u
\]
for all $k, l, m, n, r, s, t, u$. In particular, it is true for $k = l = m = n$
and $r = s = t = u$ so that $\lambda_k^4 = \lambda_r^4$ or $\lambda_k = \pm
\lambda_r$.
\end{enumerate}

\item The transformation
\[
T = \begin{bmatrix}\cos\theta&\sin\theta\\-\sin\theta&\cos\theta\end{bmatrix}
\]
is a rotation by an angle $\theta$ therefore it is angle-preserving. 
Nevertheless, one can formally confirm its nature by checking if it is norm-
preserving. Consider 
\[
y = T(x) = \begin{bmatrix}x^1\cos\theta + x^2\sin\theta \\ 
-x^1\sin\theta + x^2\cos\theta\end{bmatrix}
\]
so that
\begin{eqnarray*}
\norm{y} &=& (x^1)^2\cos^2\theta + (x^2)^2\sin^2\theta + 2x^1x^2\sin\theta
\cos\theta \\
 & & + (x^1)^2\sin^2\theta + (x^2)^2\cos^2\theta - 2x^1x^2\sin\theta
\cos\theta \\
 &=& (x^1)^2 + (x^2)^2 \\
 &=&  \norm{x}.
\end{eqnarray*}

\item $T$ is a fixed linear transformation. Let $h = (h^1, \ldots, h^m)$,
then the $j$th component of $T(h)$ is $T(h)^j = T_{ij}h^j$ and the norm of
$T(h)$ is
\[
\norm{T(h)} = \sum_{j=1}^m (T_{ij}h^j)^2
\]
Let $M$ be the largest among $\abs{T_{ij}}$ so that
\[
\norm{T(h)} \le M \sum_{j=1}^m (h^j)^2 = M\norm{h}.
\]
\begin{rem} This exercise shows that a linear transformation does not lead to
a blow up.
\end{rem}

\item Quite straightforward.

\item $T : \sor^n \rightarrow (\sor^n)^\ast$ is such that $T(x) = \varphi_x$.
Consider $T(x_1 + x_2) = \varphi_{x_1 + x_2}$ so that
\begin{eqnarray*}
T(x_1 + x_2)(y) &=& \varphi_{x_1+x_2}(y) \\
 &=& \ip{x_1+x_2}{y} \\
 &=& \ip{x_1}{y} + \ip{x_2}{y} \\
 &=& \varphi_{x_1}(y) + \varphi_{x_2}(y) \\
 &=& T(x_1)(y) + T(x_2)(y) \\
 &=& (T(x_1) + T(x_2))(y)
\end{eqnarray*}
\begin{rem}
$\varphi_x$ is called a linear functional. The space of all linear functionals,
the dual space $(\sor^n)^\ast$ is a linear space so is the set of 
transformations $T(x) = \varphi_x$.
\end{rem}

\item Follows immediately from the fact that $\norm{x+y}^2 = \ip{x+y}{x+y}$ 
and the linearity of the inner product.
\end{enumerate}

\subsection{Some theorems used to solve the problems}
\begin{thm}\label{c1s1t2}
If $f$ is a real-valued continuous function on $[a, b]$ and 
\[
\int_a^b f^2 = 0
\]
then $f = 0$.
\end{thm}
\begin{proof}
The integrand is non-negative and continuous throughout $[a, b]$. Let it take 
a positive value $c$ for some $x_0 \in [a, b]$. Then there is neighbourhood
$(x_0 - \delta, x_0 + \delta$ in which the integrand is positive and hence
\[
\int_{x_0 - \delta}^{x_0 + \delta} f^2 > 0.
\]
But
\[
\int_a^b f^2 \ge \int_{x_0 - \delta}^{x_0 + \delta} f^2 > 0,
\]
a contradiction. 
\end{proof}

\begin{thm}\label{c1s1t3}
If $f$ is a real-valued integrable function on $[a, b]$ and 
\[
\int_a^b f^2 = 0
\]
then $f = 0$ a.e..
\end{thm}
\begin{proof}
Suppose $f = 0$ a.e. is not true. Then create sets 
\begin{eqnarray*}
B_0 &=& \left\{x \in [a, b]: f^2 \ge 1\right\} \\
B_n &=& \left\{x \in [a, b] : \frac{1}{n-1} > f^2 \ge \frac{1}{n}\right\}
\end{eqnarray*}
where $n > 1$ is an integer. The sets $\{B_n\}$ are disjoint and the integral is
just the sum of measures of each of these sets. When $f = 0$ a.e. is not true
at least one of these sets, say $B_k$, will have a positive measure, in which
case
\[
\int_a^b f^2 > \frac{\mu(B_k)}{k} > 0,
\]
a contradiction.

\end{proof}

\section{Subsets of euclidean sets}\label{c1s2}
\begin{lem}\label{c1s2l1}
Every set $X$ has an open cover.
\end{lem}
\begin{proof}
$\{\cup_x B_\epsilon(x) : x \in X, \epsilon > 0\}$ is an open cover, where 
$B_\epsilon(x)$ is an open ball of radius $\epsilon$ centred at $x$.
\end{proof}

\begin{thm}[Heine-Borel]\label{c1s2t1}
$[a, b]$ is compact.
\end{thm}
\begin{proof}
Let $\mathcal{O}$ be an open cover of $[a, b]$ and define the set
\[
X = \{x : [a, x] \text{ has a finite open cover}\}.
\]
The set $X$ is non-empty because $a \in X$. It is also bounded. Therefore, it
has a supremum, say $L$. 

$L \in X$. Since $L = \sup X$, for any $\epsilon > 0$, $L - \epsilon \in X$.
Choose $\epsilon$ such that it is the radius of one of the member of 
$\mathcal{O}$ that covers $L$. But this means that $[a, L]$ has a finite cover
and hence $L \in X$.

$L = b$. If it did not then consider an open set of radius $\epsilon$ that
covers $L$. Then $L + \epsilon$ will also be in $X$ contradicting the fact
that $L = \sup X$.
\end{proof}

\begin{lem}\label{c1s2l2}
If $B \subset \sor^m$ is a compact set then for any $x \in \sor^n$, the set
$\{x\} \times B$ is compact.
\end{lem}
\begin{proof}
The finite open cover $A_1, \ldots, A_k$ of $B$ can be extended to $\{x\} \times
A_1, \ldots, \{x\} \times A_k$, which is a finite open cover of $\{x\}\times B$.
\end{proof}

\begin{thm}\label{c1s2t2}
If $B \subset \sor^m$ is a compact set and $\mathcal{O}$ is an open cover of
$\{x\} \times B$, for an $x \in \sor^n$, then there exists a subset $U$ of
$\sor^n$, containing $x$, such that $U \times B$ is covered by a finite number
of members of $\mathcal{O}$.
\end{thm}
\begin{proof}
From \eqref{c1s2l1} we can assume that $\mathcal{O}$ is a finite set. Consider
$\{x\} \times B$. Let $\{x\} \times W_1, \ldots \{x\} \times W_k$ be its cover.
Each one of these has an open rectangle $Q_1 \times R_1, \ldots R_k \times Q_k$
such that $Q_1, \ldots Q_k$ are subsets of $\sor^n$ and $R_1, \ldots, R_k$ are
subsets of $\sor^m$. Let $U = Q_1 \cap \cdots \cap Q_k$. Then $U \times B$ is
covered by $Q_1 \times R_1, \ldots, Q_k \times R_k$.
\end{proof}

This theorem assures that one can always extend the finite open cover of a 
subset of $\sor^m$ to an open cover of a subset of $\sor^n \times \sor^m$.

\begin{prop}\label{c1s2p1}
If $A \subset \sor^n$ and $B \subset \sor^m$ are compact then $A \times B 
\subset \sor^n \times \sor^m$ is compact.
\end{prop}
\begin{proof}
If $U_1, \ldots, U_k$ is an open cover of $A$ and $V_1, \ldots, V_l$ that of
$B$ then the sets $U_i \times V_j$ where $i = 1, \ldots, k$ and $j = 1, \ldots,
l$ is a finite open cover of $A \times B$.
\end{proof}

As a result of theorem \ref{c1s2t1} and proposition \ref{c1s2p1} we have
\begin{lem}\label{c1s2l3}
A closed bounded set of $\sor^n$ is compact.
\end{lem}

\subsection{Some additional lemmas}
\begin{lem}\label{c1s2l4}
A set if open if every element of it lies in a open ball entirely in the set.
\end{lem}
\begin{proof}
By definition, a set is open if every element of it lies in an open hyper-
rectangle entirely in the set. Choose the rectangle to be a hypercube of side 
$a$ centered at the element. Then we can enclose a ball of radius $a/2$ with 
centre coinciding the hypercube's centre.
\end{proof}

\subsection{Problems}
\begin{enumerate}
\item It is easy to check that a union, countable or not, of open sets is open.
Now consider a finite intersection of open sets. If $x \in U_1, \ldots, U_k$
then there are open balls $B^1_{\epsilon_1}(x), \ldots, B^k_{\epsilon_k}(x)$
entirely in $U_1, \ldots, U_k$. The ball $B_\epsilon(x)$ where $\epsilon = 
\min(\epsilon_1, \ldots, \epsilon_k)$ lies entirely in $U_1 \cap \cdots U_k$,
making it an open set.

Infinite unions may not be open because the infimum of $\epsilon_1, \epsilon_2,
\ldots$ may be zero leaving us with a singleton set after taking an intersection
and a singleton set is always closed.

As an example consider the open sets is $U_n = (-1/n, 1/n)$, $n \in \soi^+$.
Their intersection is $\{0\}$.

\begin{rem}
That is why a topological space is defined as the pair $(X, \tau)$, where $\tau$
is a collection of subsets of $X$ such that
\begin{enumerate}
\item $X$ and $\varnothing$ belong to $\tau$.
\item An arbitrary union of sets of $\tau$ belong to $\tau$.
\item A \underline{finite} intersection of sets of $\tau$ belong to $\tau$.
\end{enumerate}
We want a topological space to be closed under operations on open sets.
\end{rem}

\item Proved as lemma \ref{c1s2l4}.

\item 
\begin{enumerate}
\item[(a)] $U = \{x \in \sor^n : \norm{x} \le 1\}$. The interior is the open
ball $B_1(0)$, the boundary is the sphere $S^2$ and the exterior is everything
outside it.
\item[(b)] $S^2 = \{x \in \sor^n : \norm{x} = 1\}$. There is no interior. 
Neither is there any exterior. $S^2$ is its own boundary.
\item[(c)] $U = \{x \in \sor^n : x^i \in \soq\}$. There is no neighbourhood of 
$x \in U$ with points only in $U$. The same is true for the set $\sor^n - U$.
Therefore, $U$ is neither open nor closed. It has no interior or exterior and
it is its own boundary.
\end{enumerate}

\item If $A$ was defined as $(0, 1) \times (0, 1)$ and there was no mention of
the boundary then a diagonal line would have met the restrictions of the 
problem.

If $A = [0, 1] \times [0, 1]$ then let $i_n, j_n = 2^{-n}$ for all $n \in \son$.
Then the points $H=\{0, i_n, 1 - i_n, 1\}$ divide $[0, 1]$ in $n$ intervals of
equal length. Same is true for the points $V = \{0, j_n, 1 - j_n, 1\}$. The
set $H \times V$ defines a grid of equally sized cells of the closed rectangle
 $A$. Choose one point from each of these cells.

\item $A$ is an open set and is a subset of $[0, 1]$. The boundary of $A$
contains points all neighbourhoods of which contain some points in $A$ and
some in its exterior. If $E$ is the exterior of $A$ and $\partial A$ is its
boundary then $E \cap \partial A = [0, 1] - A$.

It suffices to show that $E$ is empty. Let $x \in E$. Then there exists a
neighbourbood $(x - \epsilon, x + \epsilon)$ such that there is no point of
$A$ in it. But that is impossible because there is at least one rational number
in this neighbourhood. Thus, $E = \varnothing$ and hence $\partial A = [0, 1]
- A$.

\end{enumerate}
