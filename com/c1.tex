\chapter{Functions on Euclidean Space}\label{c1}
\section{Norm and inner product}\label{c1s1}
$\sor^n$ has points $x = (x^1, \ldots, x^n)$ such that if $\alpha \in \sor$
then $\alpha x = (\alpha x^1, \ldots, \alpha x^n)$ is also a point in $\sor^n$
and so is $x + y = (x^1 + y^1, \ldots x^n + y^n)$. $\sor^n$ is a linear vector
space. 
\begin{defn}\label{c1s1d1}
The norm of a vector $x \in \sor^n$ is defined as
\[
\norm{x} = \left((x^1)^2 + \cdots + (x^n)^2\right)^{1/2}.
\]
\end{defn}

\begin{defn}\label{c1s1d2}
The inner product of vectors $x, y \in \sor$ is defined as
\[
\ip{x}{y} = \abs{\sum_{i=1}^n x^i y^i }.
\]
\end{defn}

\begin{lem}\label{c1s1l1}
$\norm{x}^2 = \ip{x}{x}$.
\end{lem}

\begin{lem}\label{c1s1l2}
$\ip{x}{y} = \ip{y}{x}$.
\end{lem}

\begin{lem}\label{c1s1l3}
$\ip{\alpha x}{y} = \alpha\ip{y}{x}$ and $\ip{x}{\alpha y} = \alpha\ip{x}{y}$
for all $\alpha \in \sor$.
\end{lem}

\begin{lem}\label{c1s1l4}
$\ip{x}{y_1 + y_2} = \ip{x}{y_1} + \ip{x}{y_2}$ and $\ip{x_1 + x_2}{y} = 
\ip{x_1}{y} + \ip{x_2}{y}$.
\end{lem}

\begin{lem}[Polarisation identity]\label{c1s1l5}
\[
\ip{x}{y} = \frac{\norm{x + y}^2 - \norm{x - y}^2}{4}.
\]
\end{lem}
\begin{proof}
Follows immediately from lemmas \ref{c1s1l1} and \ref{c1s1l2}.
\end{proof}

\begin{lem}\label{c1s1l6}
$\norm{x} = \norm{-x}$.
\end{lem}

The norm has the following properties.
\begin{thm}\label{c1s1t1}
If $x, y \in \sor^n$ and $\alpha \in \sor$ then
\begin{enumerate}
\item $\norm{x} \ge 0$ and $\norm{x} = 0$ iff $x = 0$.
\item Cauchy-Schwarz inequality
\[
\ip{x}{y} \le \norm{x}\norm{y}.
\]
the equality is true if $x = \lambda y$ for some $\lambda \in \sor$.
\item $\norm{x + y} \le \norm{x} + \norm{y}$.
\item $\norm{\alpha x} = \abs{\alpha}\norm{x}$ for all $\alpha \in \sor$.
\end{enumerate}
\end{thm}
\begin{proof}
$\norm{x}$ is the positive square root of the sum of non-negative reals. 
Therefore it is non-negative. If $x = 0$ then clearly $\norm{x} = 0$. If
$\norm{x} = 0$ then the sum of $n$ non-negative numbers is zero, which is
possible only if all of them are zero.

Consider $\norm{x - \lambda y}^2 = \ip{x - \lambda y}{x - \lambda y}$
so that
\[
\norm{x - \lambda y}^2 = \ip{x}{x} - 2\lambda\ip{x}{y}  + \lambda^2\ip{y}{y}
\]
We showed previously that $\norm{x - \lambda y} \ge 0$ and that it is zero
iff $x - \lambda y = 0$. If $\norm{x - \lambda y}^2 > 0$ then then the quadratic
on the rhs has no real roots, in which case the discriminant
\[
4\lambda^2\ip{x}{y}^2 - 4\lambda^2\norm{x}^2\norm{y}^2 < 0
\]
from which it follows that
\[
\ip{x}{y} < {\norm{x}}{\norm{y}}.
\]
If, on the other hand, $\norm{x - \lambda y} = 0$ then the quadratic has real
roots in which case $\ip{x}{y} \ge {\norm{x}}{\norm{y}}$. However, if $\norm{x -
\lambda y} = 0$ then $x = \lambda y$ and then $\ip{x}{y} = {\norm{x}}
{\norm{y}}$. In either case, $\ip{x}{y} \le {\norm{x}} {\norm{y}}$. Now suppose
that $\ip{x}{y} = \norm{x}\norm{y}$ then the discriminant of the quadratic
is zero which indicates that real roots exist and that $x = \lambda y$.

$\norm{x + y}^2 = \ip{x+y}{x+y} = \norm{x}^2 + 2\ip{x}{y} + \norm{y}^2$. Using
the Cauchy-Schwarz inequality, $\norm{x + y}^2 \le \norm{x}^2 + 2\norm{x}
\norm{y} + \norm{y}^2 = (\norm{x} + \norm{y})^2$.

The fourth statement follows immediately from the definitions of the scalar
product and the norm.
\end{proof}

\subsection{Problems}
\begin{enumerate}
\item We will prove by induction on $n$. If $n = 1$, $x = (x^1)$ and $\norm{x}
= \sqrt{(x^1)^2} \le \abs{x^1}$, as we always choose the positive square root.
Assume that the statement is true for all $n < k$ and consider
\[
\norm{x}^2 = \sum_{i=1}^{k-1}(x^i)^2 + (x^k)^2 \le 
\left(\sum_{i=1}^{k-1}\abs{x^i}\right)^2 + \abs{x^k}^2 = 
\left(\sum_{i=1}^k\abs{x^i}^2\right)^2.
\]

\item When is $\norm{x + y} = \norm{x} + \norm{y}$? Only when $x = \lambda y$ 
for $\lambda \ge 0$.

\item $\norm{x - y} = \norm{x + (-y)} \le \norm{x} + \norm{-y} = \norm{x} + 
\norm{y}$. Equality holds when $x = \lambda y$ with $\lambda \le 0$.

\item $\norm{x} = \norm{x - y + y} \le \norm{x - y} + \norm{y}$ so that
$\norm{x} - \norm{y} \le \norm{x - y}$. We can similarly show that $\norm{y} -
\norm{x} \le \norm{y - x} = \norm{x - y}$.

\item The length of one side of a triangle never exceeds the sum of lengths of
the other two sides.

\item Given that $f$ and $g$ are (real-valued) integrable on $[a, b]$. 
\begin{enumerate}
\item[(a)] Then
\[
\int_a^b (f - \lambda g)^2 = \int_a^b f^2 - 2\lambda\int_a^b fg + \lambda^2
\int_a^b g^2.
\]
The expression is non-negative. If suppose it is zero then $f - \lambda g = 0$
almost everywhere. If $f$ and $g$ are continuous then $f = \lambda g$, that is
the two functions are linearly dependent, in which case
\[
\int_a^b fg = \left(\int_a^b f^2\right)^{1/2}\left(\int_a^b g^2\right)^{1/2}.
\]
On the other hand, if the expression
is positive then the quadratic
\[
\lambda^2 \int_a^b g^2 - 2\lambda\int_a^b fg + \int_a^b f^2
\]
has no real roots, which is possible only when the discriminant
\[
4\lambda^2 \left(\int_a^b fg\right)^2 - 
4\lambda^2\left(\int_a^b f^2\right)\left(\int_a^b g^2\right) < 0
\]

\item[(b)] In the case of equality, $f = \lambda g$ only if both functions are
continuous. Otherwise, $f = \lambda g$ a.e. and the two are \emph{not} linearly
dependent.

\item[(c)] Part 2 of theorem \ref{c1s1t1} is a special case of this statement
because a norm defined as a sum has properties similar to an integral except
that when the norm is zero the vector is also zero.
\end{enumerate}

\item
\begin{enumerate}
\item[(a)] If $T$ is inner product preserving then $\ip{T(x)}{T(y)}=\ip{x}{y}$.
Choose $x = y$. Then $\ip{T(x)}{T(x)} = \ip{x}{y} \Rightarrow \norm{T(x)}^2 =
\norm{x}^2$ or that $T$ is norm preserving.

To prove the converse, use the polarisation identity (lemma \ref{c1s1l5})
\[
\ip{T(x)}{T(y)} = \frac{\norm{T(x) + T(y)}^2 - \norm{T(x) - T(y)}^2}{4}.
\]
Since $T$ is linear, $T(x \pm y) = T(x) \pm T(y)$ so that
is inner product preserving as well.
\[
\ip{T(x)}{T(y)} = \frac{\norm{T(x + y)}^2 - \norm{T(x - y)}^2}{4}.
\]
Since $T$ is norm preserving,
\[
\ip{T(x)}{T(y)} = \frac{\norm{x + y}^2 - \norm{x - y}^2}{4} = \ip{x}{y}.
\]

\begin{rem}
Every inner product preserving transformation is a norm-preserving 
transformation but the converse is true only if the transformation is linear.
The set of norm preserving transformations is, in general, bigger than the
set of inner-product preserving transformations.
\end{rem}

\item[(b)] Let $T$ be a norm-preserving linear transformation and let if 
possible $T(x_1) = T(x_2)$. Then $0 = \norm{T(x_1) - T(x_2)} = 
\norm{T(x_1 - x_2)} = \norm{x_1 - x_2}$ which implies that $x_1 = x_2$.

Thus, $T(e_i) \ne T(e_j)$ for all $i \ne j$ and $T$ is also onto. As a result,
$T^{-1}$ exists. To show that $T^{-1}$ is of the same sort, it suffices to show
that $T^{-1}$ is linear and norm preserving. To show that it is linear, let
$T(x_1) = y_1, T(x_2) = y_2$ and consider
\[
T^{-1}(y_1 + y_2) = T^{-1}(T(x_1) + T(x_2)).
\]
Since $T$ is linear, the right hand side is $T^{-1}(T(x_1 + x_2)) = x_1 + x_2
= T^{-1}(y_1) + T^{-1}(y_2)$. Similarly, $T^{-1}(cy_1) = T^{-1}(cT(x_1)) = 
T^{-1}T(cx_1) = cx_1 = cT^{-1}(y_1)$. To show that it is norm-preserving,
consider $\norm{T^{-1}(y_1)} = \norm{T^{-1}T(x_1)} = \norm{x_1}$. But $T$ is
norm-preserving so that we have $\norm{T^{-1}(y_1)}=\norm{T(x_1)}=\norm{y_1}$,
making $T^{-1}$ norm-preserving.
\end{enumerate}

\item 
\begin{enumerate}
\item[(a)] If $T$ is norm preserving then it is also inner-product preserving.
Therefore, it leaves the quantity
\[
\frac{\ip{x}{y}}{\norm{x}\norm{y}}
\]
invariant. 

\item[(b)] There is a mistake in the problem statement. $T$ is angle preserving
if $\lambda_1 = \ldots = \lambda_n = \lambda$. In this case, let
\begin{eqnarray*}
a &=& \alpha_1 x_1 + \cdots + \alpha_n x_n \\
b &=& \beta_1 x_1 + \cdots + \beta_n x_n 
\end{eqnarray*}
Then
\begin{eqnarray*}
\norm{a}^2 &=& \ip{a}{a} = \sum_{i,j=1}^n\alpha_i\alpha_j\ip{x_i}{x_j} \\
\norm{b}^2 &=& \ip{b}{b} = \sum_{i,j=1}^n\beta_i\beta_j\ip{x_i}{x_j} \\
\ip{a}{b} &=& \sum_{i,j=1}^n\alpha_i\beta_j\ip{x_i}{x_j}
\end{eqnarray*}
and
\begin{eqnarray*}
\norm{T(a)}^2 = \sum_{i,j=1}^n\lambda^2\alpha_i\alpha_j\ip{x_i}{x_j} \\
\norm{T(b)}^2 = \sum_{i,j=1}^n\lambda^2\beta_i\beta_j\ip{x_i}{x_j} \\
\ip{T(a)}{T(b)} = \sum_{i,j=1}^n\lambda^2\alpha_i\beta_j\ip{x_i}{x_j}
\end{eqnarray*}
so that
\[
\angle(T(a),T(b)) = \angle(a, b).
\]

To spot this mistake, consider the $2$-dimensional case with $T(x_1) = x_1,
T(x_2) = -x_2$.

Let us now examine the converse. Let $T(x_i) = \lambda_i x_i$. Introduce the
variables
\begin{eqnarray*}
A_{ij} &=& \alpha_i\alpha_j\ip{x_i}{x_j} \\
B_{ij} &=& \beta_i\beta_j\ip{x_i}{x_j} \\
C_{ij} &=& \alpha_i\beta_j\ip{x_i}{x_j}
\end{eqnarray*}
so that
\begin{eqnarray*}
\angle(a, b) &=& \frac{\sum_{r,s}C_{rs}}
                 {\sqrt{\sum_{k,l}A_{kl}}\sqrt{\sum_{m,n}B_{mn}}} \\
(\angle(a, b))^2 &=& \frac{\sum_{rstu}C_{rs}C_{tu}}
                 {\sum_{k,l}A_{kl}\sum_{m,n}B_{mn}}  \\
(\angle(T(a), T(b)))^2 &=& \frac{\sum_{rstu}\lambda_r\lambda_s\lambda_t\lambda_u
    C_{rs}C_{tu}}
    {\sum_{k,l}\lambda_k\lambda_l A_{kl}\sum_{m,n}\lambda_m\lambda_n B_{mn}} 
\end{eqnarray*}
When $T$ is angle preserving,
\[
\sum_{k,l,m,n,r,s,t,u}\lambda_k\lambda_l\lambda_m\lambda_n A_{kl}B_{mn}C_{rs}
C_{tu} = 
\sum_{k,l,m,n,r,s,t,u}\lambda_r\lambda_s\lambda_t\lambda_u A_{kl}B_{mn}C_{rs}
C_{tu}
\]
or
\[
\sum_{k,l,m,n,r,s,t,u}(\lambda_k\lambda_l\lambda_m\lambda_n - 
\lambda_r\lambda_s\lambda_t\lambda_u)A_{kl}B_{mn}C_{rs}C_{tu} = 0.
\]
This equation is true for all vectors $a, b$, that is all possible values of 
$A_{kl}, B_{mn}, C_{rs}$ and $C_{tu}$. Therefore, we must have
\[
\lambda_k\lambda_l\lambda_m\lambda_n = \lambda_r\lambda_s\lambda_t\lambda_u
\]
for all $k, l, m, n, r, s, t, u$. In particular, it is true for $k = l = m = n$
and $r = s = t = u$ so that $\lambda_k^4 = \lambda_r^4$ or $\lambda_k = \pm
\lambda_r$.
\end{enumerate}

\item The transformation
\[
T = \begin{bmatrix}\cos\theta&\sin\theta\\-\sin\theta&\cos\theta\end{bmatrix}
\]
is a rotation by an angle $\theta$ therefore it is angle-preserving. 
Nevertheless, one can formally confirm its nature by checking if it is norm-
preserving. Consider 
\[
y = T(x) = \begin{bmatrix}x^1\cos\theta + x^2\sin\theta \\ 
-x^1\sin\theta + x^2\cos\theta\end{bmatrix}
\]
so that
\begin{eqnarray*}
\norm{y} &=& (x^1)^2\cos^2\theta + (x^2)^2\sin^2\theta + 2x^1x^2\sin\theta
\cos\theta \\
 & & + (x^1)^2\sin^2\theta + (x^2)^2\cos^2\theta - 2x^1x^2\sin\theta
\cos\theta \\
 &=& (x^1)^2 + (x^2)^2 \\
 &=&  \norm{x}.
\end{eqnarray*}

\item $T$ is a fixed linear transformation. Let $h = (h^1, \ldots, h^m)$,
then the $j$th component of $T(h)$ is $T(h)^j = T_{ij}h^j$ and the norm of
$T(h)$ is
\[
\norm{T(h)} = \sum_{j=1}^m (T_{ij}h^j)^2
\]
Let $M$ be the largest among $\abs{T_{ij}}$ so that
\[
\norm{T(h)} \le M \sum_{j=1}^m (h^j)^2 = M\norm{h}.
\]
\begin{rem} This exercise shows that a linear transformation does not lead to
a blow up.
\end{rem}

\item Quite straightforward.

\item $T : \sor^n \rightarrow (\sor^n)^\ast$ is such that $T(x) = \varphi_x$.
Consider $T(x_1 + x_2) = \varphi_{x_1 + x_2}$ so that
\begin{eqnarray*}
T(x_1 + x_2)(y) &=& \varphi_{x_1+x_2}(y) \\
 &=& \ip{x_1+x_2}{y} \\
 &=& \ip{x_1}{y} + \ip{x_2}{y} \\
 &=& \varphi_{x_1}(y) + \varphi_{x_2}(y) \\
 &=& T(x_1)(y) + T(x_2)(y) \\
 &=& (T(x_1) + T(x_2))(y)
\end{eqnarray*}
\begin{rem}
$\varphi_x$ is called a linear functional. The space of all linear functionals,
the dual space $(\sor^n)^\ast$ is a linear space so is the set of 
transformations $T(x) = \varphi_x$.
\end{rem}

\item Follows immediately from the fact that $\norm{x+y}^2 = \ip{x+y}{x+y}$ 
and the linearity of the inner product.
\end{enumerate}

\subsection{Some theorems used to solve the problems}
\begin{thm}\label{c1s1t2}
If $f$ is a real-valued continuous function on $[a, b]$ and 
\[
\int_a^b f^2 = 0
\]
then $f = 0$.
\end{thm}
\begin{proof}
The integrand is non-negative and continuous throughout $[a, b]$. Let it take 
a positive value $c$ for some $x_0 \in [a, b]$. Then there is neighbourhood
$(x_0 - \delta, x_0 + \delta$ in which the integrand is positive and hence
\[
\int_{x_0 - \delta}^{x_0 + \delta} f^2 > 0.
\]
But
\[
\int_a^b f^2 \ge \int_{x_0 - \delta}^{x_0 + \delta} f^2 > 0,
\]
a contradiction. 
\end{proof}

\begin{thm}\label{c1s1t3}
If $f$ is a real-valued integrable function on $[a, b]$ and 
\[
\int_a^b f^2 = 0
\]
then $f = 0$ a.e..
\end{thm}
\begin{proof}
Suppose $f = 0$ a.e. is not true. Then create sets 
\begin{eqnarray*}
B_0 &=& \left\{x \in [a, b]: f^2 \ge 1\right\} \\
B_n &=& \left\{x \in [a, b] : \frac{1}{n-1} > f^2 \ge \frac{1}{n}\right\}
\end{eqnarray*}
where $n > 1$ is an integer. The sets $\{B_n\}$ are disjoint and the integral is
just the sum of measures of each of these sets. When $f = 0$ a.e. is not true
at least one of these sets, say $B_k$, will have a positive measure, in which
case
\[
\int_a^b f^2 > \frac{\mu(B_k)}{k} > 0,
\]
a contradiction.

\end{proof}

\section{Subsets of euclidean sets}\label{c1s2}
\begin{lem}\label{c1s2l1}
Every set $X$ has an open cover.
\end{lem}
\begin{proof}
$\{\cup_x B_\epsilon(x) : x \in X, \epsilon > 0\}$ is an open cover, where 
$B_\epsilon(x)$ is an open ball of radius $\epsilon$ centred at $x$.
\end{proof}

\begin{thm}[Heine-Borel]\label{c1s2t1}
$[a, b]$ is compact.
\end{thm}
\begin{proof}
Let $\mathcal{O}$ be an open cover of $[a, b]$ and define the set
\[
X = \{x : [a, x] \text{ has a finite open cover}\}.
\]
The set $X$ is non-empty because $a \in X$. It is also bounded. Therefore, it
has a supremum, say $L$. 

$L \in X$. Since $L = \sup X$, for any $\epsilon > 0$, $L - \epsilon \in X$.
Choose $\epsilon$ such that it is the radius of one of the member of 
$\mathcal{O}$ that covers $L$. But this means that $[a, L]$ has a finite cover
and hence $L \in X$.

$L = b$. If it did not then consider an open set of radius $\epsilon$ that
covers $L$. Then $L + \epsilon$ will also be in $X$ contradicting the fact
that $L = \sup X$.
\end{proof}

\begin{lem}\label{c1s2l2}
If $B \subset \sor^m$ is a compact set then for any $x \in \sor^n$, the set
$\{x\} \times B$ is compact.
\end{lem}
\begin{proof}
The finite open cover $A_1, \ldots, A_k$ of $B$ can be extended to $\{x\} \times
A_1, \ldots, \{x\} \times A_k$, which is a finite open cover of $\{x\}\times B$.
\end{proof}

\begin{thm}\label{c1s2t2}
If $B \subset \sor^m$ is a compact set and $\mathcal{O}$ is an open cover of
$\{x\} \times B$, for an $x \in \sor^n$, then there exists a subset $U$ of
$\sor^n$, containing $x$, such that $U \times B$ is covered by a finite number
of members of $\mathcal{O}$.
\end{thm}
\begin{proof}
From \eqref{c1s2l1} we can assume that $\mathcal{O}$ is a finite set. Consider
$\{x\} \times B$. Let $\{x\} \times W_1, \ldots \{x\} \times W_k$ be its cover.
Each one of these has an open rectangle $Q_1 \times R_1, \ldots R_k \times Q_k$
such that $Q_1, \ldots Q_k$ are subsets of $\sor^n$ and $R_1, \ldots, R_k$ are
subsets of $\sor^m$. Let $U = Q_1 \cap \cdots \cap Q_k$. Then $U \times B$ is
covered by $Q_1 \times R_1, \ldots, Q_k \times R_k$.
\end{proof}

This theorem assures that one can always extend the finite open cover of a 
subset of $\sor^m$ to an open cover of a subset of $\sor^n \times \sor^m$.

\begin{prop}\label{c1s2p1}
If $A \subset \sor^n$ and $B \subset \sor^m$ are compact then $A \times B 
\subset \sor^n \times \sor^m$ is compact.
\end{prop}
\begin{proof}
If $U_1, \ldots, U_k$ is an open cover of $A$ and $V_1, \ldots, V_l$ that of
$B$ then the sets $U_i \times V_j$ where $i = 1, \ldots, k$ and $j = 1, \ldots,
l$ is a finite open cover of $A \times B$.
\end{proof}

As a result of theorem \ref{c1s2t1} and proposition \ref{c1s2p1} we have
\begin{lem}\label{c1s2l3}
A closed bounded set of $\sor^n$ is compact.
\end{lem}

\subsection{Some additional lemmas}
\begin{lem}\label{c1s2l4}
A set if open if every element of it lies in a open ball entirely in the set.
\end{lem}
\begin{proof}
By definition, a set is open if every element of it lies in an open hyper-
rectangle entirely in the set. Choose the rectangle to be a hypercube of side 
$a$ centered at the element. Then we can enclose a ball of radius $a/2$ with 
centre coinciding the hypercube's centre.
\end{proof}

\begin{defn}\label{c1s2d1}
A point $x$ is a limit point of a set $X$ is $B_\epsilon(x)$ contains a point
of $X$ for all $\epsilon > 0$.
\end{defn}

\begin{lem}\label{c1s2l5}
If $X$ is a closed set then it contains all its limit points.
\end{lem}
\begin{proof}
Let $x_0$ be a limit point of $X$ and $x_0 \notin X$. Since $X$ is closed,
$\sor^n - X$ is open. Since $x_0$ is a limit point of $X$, every neighbourhood
of $x_0$ has points of $X$. Therefore, there is no neighbourhood of $x_0$ with
points in $\sor^n - X$, a contradiction.
\end{proof}

\subsection{Problems}
\begin{enumerate}
\item It is easy to check that a union, countable or not, of open sets is open.
Now consider a finite intersection of open sets. If $x \in U_1, \ldots, U_k$
then there are open balls $B^1_{\epsilon_1}(x), \ldots, B^k_{\epsilon_k}(x)$
entirely in $U_1, \ldots, U_k$. The ball $B_\epsilon(x)$ where $\epsilon = 
\min(\epsilon_1, \ldots, \epsilon_k)$ lies entirely in $U_1 \cap \cdots U_k$,
making it an open set.

Infinite unions may not be open because the infimum of $\epsilon_1, \epsilon_2,
\ldots$ may be zero leaving us with a singleton set after taking an intersection
and a singleton set is always closed.

As an example consider the open sets is $U_n = (-1/n, 1/n)$, $n \in \soi^+$.
Their intersection is $\{0\}$.

\begin{rem}
That is why a topological space is defined as the pair $(X, \tau)$, where $\tau$
is a collection of subsets of $X$ such that
\begin{enumerate}
\item $X$ and $\varnothing$ belong to $\tau$.
\item An arbitrary union of sets of $\tau$ belong to $\tau$.
\item A \underline{finite} intersection of sets of $\tau$ belong to $\tau$.
\end{enumerate}
We want a topological space to be closed under operations on open sets.
\end{rem}

\item Proved as lemma \ref{c1s2l4}.

\item 
\begin{enumerate}
\item[(a)] $U = \{x \in \sor^n : \norm{x} \le 1\}$. The interior is the open
ball $B_1(0)$, the boundary is the sphere $S^2$ and the exterior is everything
outside it.
\item[(b)] $S^2 = \{x \in \sor^n : \norm{x} = 1\}$. There is no interior. 
Neither is there any exterior. $S^2$ is its own boundary.
\item[(c)] $U = \{x \in \sor^n : x^i \in \soq\}$. There is no neighbourhood of 
$x \in U$ with points only in $U$. The same is true for the set $\sor^n - U$.
Therefore, $U$ is neither open nor closed. It has no interior or exterior and
it is its own boundary.
\end{enumerate}

\item If $A$ was defined as $(0, 1) \times (0, 1)$ and there was no mention of
the boundary then a diagonal line would have met the restrictions of the 
problem.

If $A = [0, 1] \times [0, 1]$ then let $i_n, j_n = 2^{-n}$ for all $n \in \son$.
Then the points $H=\{0, i_n, 1 - i_n, 1\}$ divide $[0, 1]$ in $n$ intervals of
equal length. Same is true for the points $V = \{0, j_n, 1 - j_n, 1\}$. The
set $H \times V$ defines a grid of equally sized cells of the closed rectangle
 $A$. Choose one point from each of these cells.

\item $A$ is an open set and is a subset of $[0, 1]$. The boundary of $A$
contains points all neighbourhoods of which contain some points in $A$ and
some in its exterior. If $E$ is the exterior of $A$ and $\partial A$ is its
boundary then $E \cap \partial A = [0, 1] - A$.

It suffices to show that $E$ is empty. Let $x \in E$. Then there exists a
neighbourbood $(x - \epsilon, x + \epsilon)$ such that there is no point of
$A$ in it. But that is impossible because there is at least one rational number
in this neighbourhood. Thus, $E = \varnothing$ and hence $\partial A = [0, 1]
- A$.

\item Let $X$ be a compact set in $\sor^n$ and let $U_1, \ldots, U_k$ be its
finite, open cover. Each $U_i$ is of the form $(a_i^1, b_i^1) \times \cdots
\times (a_i^n, b_i^n)$. Let $a_0^1 = \min(a_1^1, \ldots, a_k^1), b_0^1 = \min(
b_1^1, \ldots, b_k^1), \ldots a_0^n = \min(a_1^n, \ldots, a_k^n), b_0^n = 
\min(b_1^n, \ldots, b_k^n)$ so that the set $X$ is bounded by $[a_0^1, b_0^1]
\times \cdots \times [a_0^n, b_0^n]$.

To show that $X$ is closed consider an arbitrary limit point $x_0$ of $X$. Let,
if possible, $x_0$ not be in $X$. Consider a family of open sets
\[
U_n = \{\sor^n - B_{n^{-1}}(x_0) : n \in \soi^+\}.
\]
This is an open cover of $X$. Since $X$ is compact, there exists $m > 0$ such
that $U_1, \ldots, U_m$ cover $X$. Therefore, the points in $B_{m^{-1}}(x_0)$
do not belong to $X$, which implies that $x_0$ is not a limit point of $X$.

\item
\begin{enumerate}
\item $A$ is closed and $y \notin A$. Therefore, $y$ is not a limit point of 
$A$. Therefore, there exists $d > 0$ such that $B_d(y)$ lies outside $A$. 
That is, for all $x \in A$, $\norm{x - y} > d$.

\item Consider the set $\{||x - y|| : x \in A, y \in B\}$. It is bounded below
and therefore has an infimum, say $d_0 \ge 0$. Let $x_0 \in A$ and $y_0 \in B$
be such that $\norm{x_0 - y_0} = d_0$. Consider the set of points $\{x(\lambda)
= x_0 + \lambda(y_0 - x_0) : \lambda \in [0, 1]\}$. This is the straight line 
joining $x_0$ and $y_0$. There exists $\mu \in [0, 1]$ such that $x(\mu)$
is neither in $A$ nor in $B$. For if not, there would be two possibilities:
\begin{itemize}
\item $x(\lambda) \in A$ for all $\lambda \le \mu$ and $x(\lambda) \in B$ for
all $\lambda > \mu$. The sets $U_n = \{B_{n^{-1}}(x_0 + \mu(y_0 - x_0)) : n 
\in \soi^+\}$ form an open cover of $B$. Since $B$ is compact, there exists 
$m > 0$ such that $U_m$ does not cover $B$. Therefore, for $\mu < \lambda < 
\mu + m^{-1}$, $x(\lambda) \notin B$, contradicting the assumption that $
x(\lambda) \in B$ for all $\lambda > \mu$.

\item $x(\lambda) \in A$ for all $\lambda < \mu$ and $x(\lambda) \in B$ for
all $\lambda \ge \mu$. This is ruled out because if $x(\mu)$ is a limit point
of $A$ and $A$ is closed.
\end{itemize}

Since $x(\mu) \notin A$ and $x(\mu)$ is also not a limit point of $A$, there 
exists $d_1 > 0$ such that $B_{d_1}(x(\mu))$ and $A$ are disjoint so that for 
all $x \in A$, $\norm{x - x(\mu)} > d_1$. 

Since $x(\mu) \notin B$ and $B$ is compact, there exists $d_2 > 0$ such that
$B_{d_2}(x(\mu)) \cap B = \varnothing$ so that for all $y \in B$, $\norm{y -
x(\mu)} > d_2$.

Therefore, $\norm{x - y} \le \norm{x - x(\mu)} + \norm{x(\mu) - y} < d_1+d_2$.

\item Consider the sets $A = \{(x^1, x^2) : x^1 x^2 \ge 1, x^2 > 0\}$ and $B = 
\{(x^1, x^2) : x^1 x^2 \le -1, x^2 > 0\}$. $A$ is the region about the hyperbola
$x^1x^2 = 1$ and $B$ is the region above the hyperbola $x^1x^2 = -1$. The two
sets are closed because they contain all their limit points. However, neither
is compact. As $x^2 \rightarrow \infty$, the two sets get closer to each other
and there is no $d > 0$ such that their elements are at least a distance $d$
apart.
\end{enumerate}

\item Given that $U$ is open, $C$ is compact, $C \subset U$ so that, $U^c$ is 
closed $C \cap U^c = \varnothing$. Therefore, (from the previous exercise),
there exits $d > 0$ such that for all $x \in C, y \in U^c$, $\norm{x - y} \ge
d$.

Define the collection $\{B_{d/2}(x) | x \in U\}$. It is an open cover of $U$
and $C \subset U$. Since $C$ is compact, there is finite subcover, say $
B_{d/2}(x_1) \cup \cdots \cup B_{d/2}(x_n)$ that covers $C$.

Let 
\[
D = \overline{\cup_{i=1}^n B_{d/2}(x_i)}
\]
then clearly $C \subset D \subset U$. Further, if $X$ is an open set then 
$X$ lies in the interior of $\overline{X}$.
\end{enumerate}

\section{Functions and continuity}\label{c1s3}
\begin{defn}\label{c1s3d1}
Consider a function $f: \sor^n \rightarrow \sor^m$. Then
\[
\lim_{x \rightarrow a}f(x) = b
\]
if for any $\epsilon > 0$, there exists $\delta > 0$ such that for all $0 < 
\norm{x - a} \le \delta$, $\norm{f(x) -b} \le \epsilon$.
\end{defn}
\begin{rem}
$f$ need not be defined at $x = a$ for its limit to be defined at $x = a$.
\end{rem}

\begin{defn}\label{c1s3d2}
Consider a function $f: \sor^n \rightarrow \sor^m$. $f$ is said to be continuous
at $x = a$ if for any $\epsilon > 0$, there exists $\delta > 0$ such that 
$\norm{x - a} \le \delta \Rightarrow \norm{f(x) - f(a)} \le epsilon$.
\end{defn}
\begin{rem}
$f$ must be defined at $x = a$ for it to be continuous at $x = a$.
\end{rem}

\begin{thm}\label{c1s3t1}
If $A \subset \sor^n$ and $f: A \rightarrow \sor^m$. Then $f$ is continuous
on $A$ if and only if for every open set $U \subset \sor^m$, there is an open 
set $V \subset \sor^n$ sich that $f^{-1}(U) = V \cap A$.
\end{thm}
\begin{proof}
Assume that $f$ is continuous in $A$. Let $U$ be an open set in $\sor^m$.
Let $a \in f^{-1}(U)$. By continuity of $f$ in A, for any $\epsilon > 0$, there
exists $\delta > 0$ such that $x \in B_\delta(a) \Rightarrow f(x) \in B_\epsilon
(f(a))$. Now the open ball $B_\delta(a)$ need not lie entirely in $A$. Therefore, we say that for any $B_\epsilon(f(a))$ there exists a set $A \cap B_\delta(a)$
such that $x \in A \cap B_\delta(a) \Rightarrow f(x) \in B_\epsilon(f(a))$. This
is true for all points $a \in A$.

To prove the converse, let $U = B_\epsilon(y)$, where $y \in \sor^m$. Then
there exists an open set $V \subset \sor^n$ such that $f^{-1}(U) = V \cap A$.
Choose $\delta$ such that $B_\delta(f^{-1}(y)) \subset V \cap A$. This proves
the continuity of $f$.
\end{proof}

\begin{rem}
The greatest significance of this theorem is that one can gets an equivalent
definition of continuity that does not require limits.
\end{rem}

Continuous functions have several useful properties.
\begin{thm}\label{c1s3t2}
If $f: A \rightarrow \sor^m$ is continuous where $A \subset \sor^n$ and $A$
is compact then $f(A)$ is also compact.
\end{thm}
\begin{proof}
Since $A$ is compact, it has a finite open cover. Since $f$ is continuous, it
maps an open set in $A$ to an open set in $f(A)$. Thus, $f(A)$ can be covered
with a finite number of open sets.
\end{proof}

\begin{rem}
What about the converse? Functions can be many-to-one. Continuity guarantees
that the pre-image is open but it cannot guarantee that it is finite. $f(x) =
\tanh(x)$, $x \in \sor$ is continuous but $\atanh([-1, 1])$ is not compact.
\end{rem}

\begin{defn}\label{c1s3d3}
Let $f: A \rightarrow \sor$ be bounded. If
\begin{eqnarray*}
M(a, f, \epsilon) &=& \sup\{f(x) : x \in B_\epsilon(a) \cap A\} \\
m(a, f, \epsilon) &=& \inf\{f(x) : x \in B_\epsilon(a) \cap A\} 
\end{eqnarray*}
then the oscillation of $f$ at $a$ is
\[
o(f, a) = \lim_{\epsilon \rightarrow 0} (M(a, f, \epsilon) - m(a, f, \epsilon)).
\]
\end{defn}

\begin{lem}\label{c1s3l1}
$o(f, a)$ always exists.
\end{lem}
\begin{proof}
Since $f$ is bounded, the infimum and supremum exist.
\end{proof}

\begin{thm}\label{c1s3t3}
A bounded function $f$ is continuous at $a$ if and only if $o(f, a) = 0$.
\end{thm}
\begin{proof}
If $f$ is continuous at $a$ then $f(x) \in B_{\epsilon}(f(a))$ or $M(x, f, a)
= f(a) + \epsilon$ and $m(x, f, a) = f(a) - \epsilon$ from which it follows
that $o(f, a) = 0$.

Conversely, if $o(f, a) = 0$ then as $\delta \rightarrow 0$, $M(a,f,\delta)
- m(a, f, \delta) < \epsilon \Rightarrow f(x) \in (f(a) - \epsilon/2, f(a) + 
\epsilon/2)$.
\end{proof}

\subsection{Problems}
\begin{enumerate}
\item If 
\[
\lim_{x \rightarrow a} f^i(x) = b^i
\]
for all $i = 1, \ldots, m$ then it is clear that $f(x) = (f^1(x), \ldots,
f^m(x)) \rightarrow (b^1, \ldots, b^m) = b$ as $x \rightarrow a$.

To prove the converse, note that 
\[
\norm{f(x) - b}^2 = \sum_{i=1}^m (f^i(x) - b^i)^2 < \epsilon^2 \Rightarrow
\abs{f^i(x) - b^i} < \epsilon.
\]

\item If $f^i$ is continuous at $a$ then $\abs{f^i(x) - f^i(a)} < \epsilon/
\sqrt{m}$ and
\[
\norm{f(x) - f(a)}^2 = \sum_{i=1}^m \abs{f^i(x) - f^i(a)}^2 < \epsilon^2
\Rightarrow \norm{f(x) - f(a)} < \epsilon.
\]

Conversely, 
\[
\norm{f(x) - f(a)}^2 < \epsilon^2 \Rightarrow \abs{f^i(x) - f^i(a)}
^2 < \epsilon^2 \Rightarrow \abs{f^i(x) - f^i(a)} < \epsilon.
\]

\item Let $T: \sor^n \rightarrow \sor^m$ be a linear transformation. Consider
$T(x + h) - T(x) = T(h) \le M\norm{h}$, by problem 10 of section \ref{c1s1}.
Therefore, if $\norm{h} < \epsilon/M$ then $\norm{T(x + h) - T(x)} < \epsilon$.

\item The set $A$ is the region in the first quadrant between the $x$-axis and
the parabola $y = x^2$.
\begin{enumerate}
\item A straightline that does not cut through $A$ surely has an interval
aroung the origin in $R^2 - A$ because the entire line lies in $R^2 - A$. A 
line that cuts $A$ still has an interval around the origin in $R^2 - A$
because for small $x$, $y = x^2 < mx$ and therefore the line is entirely in $R^2
- A$.

\item $f$ is the indicator function for $A$. For $h \in \sor^2$, define 
$g_h: \sor \rightarrow \sor = f(th)$. Thus, $g_h(t) = 1$ if $th \in A$ else it
is zero. To show that $g_h(t)$ is continuous at $t = 0$, consider an interval
$(-\delta, \delta)$. Any line through the origin has an interval around the 
origin entirely in $R^2 - A$ on which $g_h(t)$ takes the value $0$. Therefore,
$g_h$ as a function of $t$ is continuous at the origin.

However $f(h)$ is not continuous because it takes a value $1$ if we approach
$0$ from the positive $x$ axis and it takes a value $0$ if we approach from
any other side.
\end{enumerate}

\item The function $f(x) = \norm{x - a}$ is continuous.

\item $A$ is not closed. Therefore, there is at least one limit point of $A$,
say $x_0$, that is not part of $A$. The function $f = \norm{x - x_0}^{-1}$ is
an example of a continuous but unbounded function on $A$.

\item Since $A$ is compact and $f: A \rightarrow \sor$ is continuous, $f(A)$
is compact. Since $f(A) \subset \sor$, its compactness means that $f(A)$ is 
also closed and bounded. Therefore $\sup(A), \inf(A) \in f(A)$ so that
there are $x_m, x_M \in A$ such that $f(x_m) = \inf(A)$ and $f(x_M) = \sup(A)$.

\item $f:[a, b] \rightarrow \sor$ is an increasing function. Without loss of
generality, assume that $a < x_1 < \ldots, < x_n < b$. Now, 
\[
o(f, x_i) = \lim_{\delta \rightarrow 0}(M(x_i, f, \delta) - m(x_i, f, \delta))
\]
so that
\[
\sum_{i=1}^n o(f, x_i) = \lim_{\delta \rightarrow 0} \sum_{i=1}^n
(M(x_i, f, \delta) - m(x_i, f, \delta))
\]
Since $f$ is increasing,
\begin{eqnarray*}
M(x_i, f, \delta) &\le& f\left(\frac{x_i + x_{i+1}}{2}\right) \\
m(x_i, f, \delta) &\ge& f\left(\frac{x_{i-1} + x_i}{2}\right) 
\end{eqnarray*}
for any $\delta > 0$. Therefore, 
\[
\sum_{i=1}^n o(f, x_i) \le \sum_{i=1}^n f\left(\frac{x_i + x_{i+1}}{2}\right) -
f\left(\frac{x_{i-1} + x_i}{2}\right) = f\left(\frac{b + x_n}{2}\right) - 
f\left(\frac{a + x_1}{2}\right).
\]
The result follows from the fact that 
\begin{eqnarray*}
f(a) &<& f\left(\frac{a + x_1}{2}\right) \\
f(b) &>& f\left(\frac{b + x_n}{2}\right).
\end{eqnarray*}

\end{enumerate}


