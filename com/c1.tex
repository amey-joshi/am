\chapter{Functions on Euclidean Space}\label{c1}
\section{Norm and inner product}\label{c1s1}
$\sor^n$ has points $x = (x^1, \ldots, x^n)$ such that if $\alpha \in \sor$
then $\alpha x = (\alpha x^1, \ldots, \alpha x^n)$ is also a point in $\sor^n$
and so is $x + y = (x^1 + y^1, \ldots x^n + y^n)$. $\sor^n$ is a linear vector
space. 
\begin{defn}\label{c1s1d1}
The norm of a vector $x \in \sor^n$ is defined as
\[
\norm{x} = \left((x^1)^2 + \cdots + (x^n)^2\right)^{1/2}.
\]
\end{defn}

\begin{defn}\label{c1s1d2}
The inner product of vectors $x, y \in \sor$ is defined as
\[
\ip{x}{y} = \abs{\sum_{i=1}^n x^i y^i }.
\]
\end{defn}

\begin{lem}\label{c1s1l1}
$\norm{x}^2 = \ip{x}{x}$.
\end{lem}

\begin{lem}\label{c1s1l2}
$\ip{x}{y} = \ip{y}{x}$.
\end{lem}

\begin{lem}\label{c1s1l3}
$\ip{\alpha x}{y} = \alpha\ip{y}{x}$ and $\ip{x}{\alpha y} = \alpha\ip{x}{y}$
for all $\alpha \in \sor$.
\end{lem}

\begin{lem}\label{c1s1l4}
$\ip{x}{y_1 + y_2} = \ip{x}{y_1} + \ip{x}{y_2}$ and $\ip{x_1 + x_2}{y} = 
\ip{x_1}{y} + \ip{x_2}{y}$.
\end{lem}

\begin{lem}[Polarisation identity]\label{c1s1l5}
\[
\ip{x}{y} = \frac{\norm{x + y}^2 - \norm{x - y}^2}{4}.
\]
\end{lem}
\begin{proof}
Follows immediately from lemmas \ref{c1s1l1} and \ref{c1s1l2}.
\end{proof}

\begin{lem}\label{c1s1l6}
$\norm{x} = \norm{-x}$.
\end{lem}

The norm has the following properties.
\begin{thm}\label{c1s1t1}
If $x, y \in \sor^n$ and $\alpha \in \sor$ then
\begin{enumerate}
\item $\norm{x} \ge 0$ and $\norm{x} = 0$ iff $x = 0$.
\item Cauchy-Schwarz inequality
\[
\ip{x}{y} \le \norm{x}\norm{y}.
\]
the equality is true if $x = \lambda y$ for some $\lambda \in \sor$.
\item $\norm{x + y} \le \norm{x} + \norm{y}$.
\item $\norm{\alpha x} = \abs{\alpha}\norm{x}$ for all $\alpha \in \sor$.
\end{enumerate}
\end{thm}
\begin{proof}
$\norm{x}$ is the positive square root of the sum of non-negative reals. 
Therefore it is non-negative. If $x = 0$ then clearly $\norm{x} = 0$. If
$\norm{x} = 0$ then the sum of $n$ non-negative numbers is zero, which is
possible only if all of them are zero.

Consider $\norm{x - \lambda y}^2 = \ip{x - \lambda y}{x - \lambda y}$
so that
\[
\norm{x - \lambda y}^2 = \ip{x}{x} - 2\lambda\ip{x}{y}  + \lambda^2\ip{y}{y}
\]
We showed previously that $\norm{x - \lambda y} \ge 0$ and that it is zero
iff $x - \lambda y = 0$. If $\norm{x - \lambda y}^2 > 0$ then then the quadratic
on the rhs has no real roots, in which case the discriminant
\[
4\lambda^2\ip{x}{y}^2 - 4\lambda^2\norm{x}^2\norm{y}^2 < 0
\]
from which it follows that
\[
\ip{x}{y} < {\norm{x}}{\norm{y}}.
\]
If, on the other hand, $\norm{x - \lambda y} = 0$ then the quadratic has real
roots in which case $\ip{x}{y} \ge {\norm{x}}{\norm{y}}$. However, if $\norm{x -
\lambda y} = 0$ then $x = \lambda y$ and then $\ip{x}{y} = {\norm{x}}
{\norm{y}}$. In either case, $\ip{x}{y} \le {\norm{x}} {\norm{y}}$. Now suppose
that $\ip{x}{y} = \norm{x}\norm{y}$ then the discriminant of the quadratic
is zero which indicates that real roots exist and that $x = \lambda y$.

$\norm{x + y}^2 = \ip{x+y}{x+y} = \norm{x}^2 + 2\ip{x}{y} + \norm{y}^2$. Using
the Cauchy-Schwarz inequality, $\norm{x + y}^2 \le \norm{x}^2 + 2\norm{x}
\norm{y} + \norm{y}^2 = (\norm{x} + \norm{y})^2$.

The fourth statement follows immediately from the definitions of the scalar
product and the norm.
\end{proof}

\subsection{Problems}
\begin{enumerate}
\item We will prove by induction on $n$. If $n = 1$, $x = (x^1)$ and $\norm{x}
= \sqrt{(x^1)^2} \le \abs{x^1}$, as we always choose the positive square root.
Assume that the statement is true for all $n < k$ and consider
\[
\norm{x}^2 = \sum_{i=1}^{k-1}(x^i)^2 + (x^k)^2 \le 
\left(\sum_{i=1}^{k-1}\abs{x^i}\right)^2 + \abs{x^k}^2 = 
\left(\sum_{i=1}^k\abs{x^i}^2\right)^2.
\]

\item When is $\norm{x + y} = \norm{x} + \norm{y}$? Only when $x = \lambda y$ 
for $\lambda \ge 0$.

\item $\norm{x - y} = \norm{x + (-y)} \le \norm{x} + \norm{-y} = \norm{x} + 
\norm{y}$. Equality holds when $x = \lambda y$ with $\lambda \le 0$.

\item $\norm{x} = \norm{x - y + y} \le \norm{x - y} + \norm{y}$ so that
$\norm{x} - \norm{y} \le \norm{x - y}$. We can similarly show that $\norm{y} -
\norm{x} \le \norm{y - x} = \norm{x - y}$.

\item The length of one side of a triangle never exceeds the sum of lengths of
the other two sides.

\item Given that $f$ and $g$ are (real-valued) integrable on $[a, b]$. 
\begin{enumerate}
\item[(a)] Then
\[
\int_a^b (f - \lambda g)^2 = \int_a^b f^2 - 2\lambda\int_a^b fg + \lambda^2
\int_a^b g^2.
\]
The expression is non-negative. If suppose it is zero then $f - \lambda g = 0$
almost everywhere. If $f$ and $g$ are continuous then $f = \lambda g$, that is
the two functions are linearly dependent, in which case
\[
\int_a^b fg = \left(\int_a^b f^2\right)^{1/2}\left(\int_a^b g^2\right)^{1/2}.
\]
On the other hand, if the expression
is positive then the quadratic
\[
\lambda^2 \int_a^b g^2 - 2\lambda\int_a^b fg + \int_a^b f^2
\]
has no real roots, which is possible only when the discriminant
\[
4\lambda^2 \left(\int_a^b fg\right)^2 - 
4\lambda^2\left(\int_a^b f^2\right)\left(\int_a^b g^2\right) < 0
\]

\item[(b)] In the case of equality, $f = \lambda g$ only if both functions are
continuous. Otherwise, $f = \lambda g$ a.e. and the two are \emph{not} linearly
dependent.

\item[(c)] Part 2 of theorem \ref{c1s1t1} is a special case of this statement
because a norm defined as a sum has properties similar to an integral except
that when the norm is zero the vector is also zero.
\end{enumerate}

\item
\begin{enumerate}
\item[(a)] If $T$ is inner product preserving then $\ip{T(x)}{T(y)}=\ip{x}{y}$.
Choose $x = y$. Then $\ip{T(x)}{T(x)} = \ip{x}{y} \Rightarrow \norm{T(x)}^2 =
\norm{x}^2$ or that $T$ is norm preserving.

To prove the converse, use the polarisation identity (lemma \ref{c1s1l5})
\[
\ip{T(x)}{T(y)} = \frac{\norm{T(x) + T(y)}^2 - \norm{T(x) - T(y)}^2}{4}.
\]
Since $T$ is linear, $T(x \pm y) = T(x) \pm T(y)$ so that
is inner product preserving as well.
\[
\ip{T(x)}{T(y)} = \frac{\norm{T(x + y)}^2 - \norm{T(x - y)}^2}{4}.
\]
Since $T$ is norm preserving,
\[
\ip{T(x)}{T(y)} = \frac{\norm{x + y}^2 - \norm{x - y}^2}{4} = \ip{x}{y}.
\]

\begin{rem}
Every inner product preserving transformation is a norm-preserving 
transformation but the converse is true only if the transformation is linear.
The set of norm preserving transformations is, in general, bigger than the
set of inner-product preserving transformations.
\end{rem}

\item[(b)] Let $T$ be a norm-preserving linear transformation and let if 
possible $T(x_1) = T(x_2)$. Then $0 = \norm{T(x_1) - T(x_2)} = 
\norm{T(x_1 - x_2)} = \norm{x_1 - x_2}$ which implies that $x_1 = x_2$.

Thus, $T(e_i) \ne T(e_j)$ for all $i \ne j$ and $T$ is also onto. As a result,
$T^{-1}$ exists. To show that $T^{-1}$ is of the same sort, it suffices to show
that $T^{-1}$ is linear and norm preserving. To show that it is linear, let
$T(x_1) = y_1, T(x_2) = y_2$ and consider
\[
T^{-1}(y_1 + y_2) = T^{-1}(T(x_1) + T(x_2)).
\]
Since $T$ is linear, the right hand side is $T^{-1}(T(x_1 + x_2)) = x_1 + x_2
= T^{-1}(y_1) + T^{-1}(y_2)$. Similarly, $T^{-1}(cy_1) = T^{-1}(cT(x_1)) = 
T^{-1}T(cx_1) = cx_1 = cT^{-1}(y_1)$. To show that it is norm-preserving,
consider $\norm{T^{-1}(y_1)} = \norm{T^{-1}T(x_1)} = \norm{x_1}$. But $T$ is
norm-preserving so that we have $\norm{T^{-1}(y_1)}=\norm{T(x_1)}=\norm{y_1}$,
making $T^{-1}$ norm-preserving.
\end{enumerate}

\item 
\begin{enumerate}
\item[(a)] If $T$ is norm preserving then it is also inner-product preserving.
Therefore, it leaves the quantity
\[
\frac{\ip{x}{y}}{\norm{x}\norm{y}}
\]
invariant. 

\item[(b)] There is a mistake in the problem statement. $T$ is angle preserving
if $\lambda_1 = \ldots = \lambda_n = \lambda$. In this case, let
\begin{eqnarray*}
a &=& \alpha_1 x_1 + \cdots + \alpha_n x_n \\
b &=& \beta_1 x_1 + \cdots + \beta_n x_n 
\end{eqnarray*}
Then
\begin{eqnarray*}
\norm{a}^2 &=& \ip{a}{a} = \sum_{i,j=1}^n\alpha_i\alpha_j\ip{x_i}{x_j} \\
\norm{b}^2 &=& \ip{b}{b} = \sum_{i,j=1}^n\beta_i\beta_j\ip{x_i}{x_j} \\
\ip{a}{b} &=& \sum_{i,j=1}^n\alpha_i\beta_j\ip{x_i}{x_j}
\end{eqnarray*}
and
\begin{eqnarray*}
\norm{T(a)}^2 = \sum_{i,j=1}^n\lambda^2\alpha_i\alpha_j\ip{x_i}{x_j} \\
\norm{T(b)}^2 = \sum_{i,j=1}^n\lambda^2\beta_i\beta_j\ip{x_i}{x_j} \\
\ip{T(a)}{T(b)} = \sum_{i,j=1}^n\lambda^2\alpha_i\beta_j\ip{x_i}{x_j}
\end{eqnarray*}
so that
\[
\angle(T(a),T(b)) = \angle(a, b).
\]

To spot this mistake, consider the $2$-dimensional case with $T(x_1) = x_1,
T(x_2) = -x_2$.

Let us now examine the converse. Let $T(x_i) = \lambda_i x_i$. Introduce the
variables
\begin{eqnarray*}
A_{ij} &=& \alpha_i\alpha_j\ip{x_i}{x_j} \\
B_{ij} &=& \beta_i\beta_j\ip{x_i}{x_j} \\
C_{ij} &=& \alpha_i\beta_j\ip{x_i}{x_j}
\end{eqnarray*}
so that
\begin{eqnarray*}
\angle(a, b) &=& \frac{\sum_{r,s}C_{rs}}
                 {\sqrt{\sum_{k,l}A_{kl}}\sqrt{\sum_{m,n}B_{mn}}} \\
(\angle(a, b))^2 &=& \frac{\sum_{rstu}C_{rs}C_{tu}}
                 {\sum_{k,l}A_{kl}\sum_{m,n}B_{mn}}  \\
(\angle(T(a), T(b)))^2 &=& \frac{\sum_{rstu}\lambda_r\lambda_s\lambda_t\lambda_u
    C_{rs}C_{tu}}
    {\sum_{k,l}\lambda_k\lambda_l A_{kl}\sum_{m,n}\lambda_m\lambda_n B_{mn}} 
\end{eqnarray*}
When $T$ is angle preserving,
\[
\sum_{k,l,m,n,r,s,t,u}\lambda_k\lambda_l\lambda_m\lambda_n A_{kl}B_{mn}C_{rs}
C_{tu} = 
\sum_{k,l,m,n,r,s,t,u}\lambda_r\lambda_s\lambda_t\lambda_u A_{kl}B_{mn}C_{rs}
C_{tu}
\]
or
\[
\sum_{k,l,m,n,r,s,t,u}(\lambda_k\lambda_l\lambda_m\lambda_n - 
\lambda_r\lambda_s\lambda_t\lambda_u)A_{kl}B_{mn}C_{rs}C_{tu} = 0.
\]
This equation is true for all vectors $a, b$, that is all possible values of 
$A_{kl}, B_{mn}, C_{rs}$ and $C_{tu}$. Therefore, we must have
\[
\lambda_k\lambda_l\lambda_m\lambda_n = \lambda_r\lambda_s\lambda_t\lambda_u
\]
for all $k, l, m, n, r, s, t, u$. In particular, it is true for $k = l = m = n$
and $r = s = t = u$ so that $\lambda_k^4 = \lambda_r^4$ or $\lambda_k = \pm
\lambda_r$.
\end{enumerate}
\end{enumerate}

\subsection{Some theorems used to solve the problems}
\begin{thm}\label{c1s1t2}
If $f$ is a real-valued continuous function on $[a, b]$ and 
\[
\int_a^b f^2 = 0
\]
then $f = 0$.
\end{thm}
\begin{proof}
The integrand is non-negative and continuous throughout $[a, b]$. Let it take 
a positive value $c$ for some $x_0 \in [a, b]$. Then there is neighbourhood
$(x_0 - \delta, x_0 + \delta$ in which the integrand is positive and hence
\[
\int_{x_0 - \delta}^{x_0 + \delta} f^2 > 0.
\]
But
\[
\int_a^b f^2 \ge \int_{x_0 - \delta}^{x_0 + \delta} f^2 > 0,
\]
a contradiction. 
\end{proof}

\begin{thm}\label{c1s1t3}
If $f$ is a real-valued integrable function on $[a, b]$ and 
\[
\int_a^b f^2 = 0
\]
then $f = 0$ a.e..
\end{thm}
\begin{proof}
Suppose $f = 0$ a.e. is not true. Then create sets 
\begin{eqnarray*}
B_0 &=& \left\{x \in [a, b]: f^2 \ge 1\right\} \\
B_n &=& \left\{x \in [a, b] : \frac{1}{n-1} > f^2 \ge \frac{1}{n}\right\}
\end{eqnarray*}
where $n > 1$ is an integer. The sets $\{B_n\}$ are disjoint and the integral is
just the sum of measures of each of these sets. When $f = 0$ a.e. is not true
at least one of these sets, say $B_k$, will have a positive measure, in which
case
\[
\int_a^b f^2 > \frac{\mu(B_k)}{k} > 0,
\]
a contradiction.

\end{proof}

\section{Subsets of euclidean sets}\label{c1s2}
\begin{thm}[Heine-Borel]
$[a, b]$ is compact.
\end{thm}
\begin{proof}
Let $\mathcal{O}$ be an open cover of $[a, b]$ and define the set
\[
X = \{x : [a, x] \text{ has a finite open cover}\}.
\]
The set $X$ is non-empty because $a \in X$. It is also bounded. Therefore, it
has a supremum, say $L$. 

$L \in X$. Since $L = \sup X$, for any $\epsilon > 0$, $L - \epsilon \in X$.
Choose $\epsilon$ such that it is the radius of one of the member of 
$\mathcal{O}$ that covers $L$. But this means that $[a, L]$ has a finite cover
and hence $L \in X$.

$L = b$. If it did not then consider an open set of radius $\epsilon$ that
covers $L$. Then $L + \epsilon$ will also be in $X$ contradicting the fact
that $L = \sup X$.
\end{proof}
